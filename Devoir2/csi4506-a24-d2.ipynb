{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**CSI 4506 Introduction à l'intelligence artificielle** <br/>\n",
        "*Devoir 2: apprentissage automatique*\n",
        "\n",
        "# Identification\n",
        "\n",
        "Nom: <br/>\n",
        "Numéro d'étudiant :\n",
        "\n",
        "Nom: <br/>\n",
        "Numéro d'étudiant :\n",
        "\n",
        "# 1. Analyse exploratoire\n",
        "\n",
        "## Exploration des données\n",
        "\n",
        "Dans ce devoir, nous utiliserons le jeu de données de prédiction du diabète, accessible via [Diabetes Prediction Dataset](https://www.kaggle.com/datasets/iammustafatz/diabetes-prediction-dataset/data). Pour réduire la complexité liée à l'exigence de connexion de Kaggle, le jeu de données a été mis à disposition sur un dépôt GitHub public :\n",
        "\n",
        "- [github.com/turcotte/csi4106-f24/tree/main/assignments-data/a2](https://github.com/turcotte/csi4106-f24/tree/main/assignments-data/a2)\n",
        "\n",
        "Vous pouvez accéder et lire le jeu de données directement depuis ce dépôt GitHub dans votre notebook Jupyter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cellule de code\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. **Charger le jeu de données et fournir un résumé de sa structure** :\n",
        "\n",
        "    - Décrivez les attributs (colonnes), leurs types de données et la variable cible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cellule de code\n",
        "url = \"https://raw.githubusercontent.com/turcotte/csi4106-f24/refs/heads/main/assignments-data/a2/diabetes_prediction_dataset.csv\"\n",
        "\n",
        "df = pd.read_csv(url)\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> | Column              |  Dtype   | -\n",
        "> | ------              |  -----   | -----\n",
        "> | gender              |  object  | \n",
        "> | age                 |  float64 | \n",
        "> | hypertension        |  int64   | \n",
        "> | heart_disease       |  int64   | \n",
        "> | smoking_history     |  object  | \n",
        "> | bmi                 |  float64 | \n",
        "> | HbA1c_level         |  float64 | \n",
        "> | blood_glucose_level |  int64   | \n",
        "> | diabetes            |  int64   | Variable Cible"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. **Analyse de la distribution des attributs** :\n",
        "\n",
        "    - Examinez la distribution de chaque attribut à l'aide de visualisations appropriées telles que des histogrammes et des boxplots. Discutez des informations obtenues, y compris la présence de valeurs aberrantes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cellule de code\n",
        "# Votre code ici\n",
        "def plot_all_attributes(df, plot_func):\n",
        "    plt.subplots(3, 3, figsize=(20,15))\n",
        "    for i, attribute in enumerate(df.columns):\n",
        "        plt.subplot(3, 3, i+1)\n",
        "        plot_func(df[attribute])\n",
        "        plt.title(attribute)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_all_attributes(df, lambda x: sns.histplot(x, kde=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_all_attributes(df, sns.boxplot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> ### Analysis of the distribution of attributes\n",
        ">\n",
        "> - gender, hypertension, heart_disease, smoking_history are categorical attributes\n",
        "> - age, bmi, HbA1c_level, blood_glucose_level are numerical attributes\n",
        "> - bmi is right skewed and has some high ouliers\n",
        "> - age seems to have a uniform distribution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> ### There are no missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. **Distribution de la variable cible** :\n",
        "\n",
        "    - Analysez la distribution de la variable cible pour identifier les déséquilibres de classes. Utilisez des diagrammes en barres pour visualiser les fréquences des classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cellule de code\n",
        "sns.histplot(df['diabetes'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot distribution of each attribute with and without diabetes\n",
        "attributes = ['gender', 'hypertension', 'heart_disease', 'smoking_history']\n",
        "\n",
        "plt.subplots(2, 2, figsize=(15,12))\n",
        "for i, attribute in enumerate(attributes):\n",
        "    plt.subplot(2, 2, i+1)\n",
        "    sns.countplot(x=attribute, hue='diabetes', data=df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. **Fractionnement des données** :\n",
        "\n",
        "    - Divisez le jeu de données en ensembles d'entraînement (80 %) et de test (20 %) en utilisant la méthode du holdout.\n",
        "\n",
        "    - Assurez-vous que ce fractionnement intervient avant tout prétraitement afin d'éviter les fuites de données."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cellule de code\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = df.drop('diabetes', axis=1)\n",
        "y = df['diabetes']\n",
        "X_train, X_test, y_train_, y_test_ = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prétraitement des données\n",
        "\n",
        "5. **Encodage des variables catégoriques** :\n",
        "\n",
        "    - Encodez les variables catégoriques. Justifiez la méthode choisie."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cellule de code\n",
        "categorical_attributes = ['gender', 'smoking_history'] # 'hypertension', 'heart_disease' are also categorical attributes but they are already in binary form and do not require encoding\n",
        "\n",
        "X_train = pd.get_dummies(X_train, columns=categorical_attributes)\n",
        "X_test = pd.get_dummies(X_test, columns=categorical_attributes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "6. **Normalisation/Standardisation des attributs numériques** :\n",
        "\n",
        "    - Normalisez ou standardisez les attributs numériques si nécessaire. Décrivez la technique utilisée (par exemple, le scaling Min-Max, StandardScaler) et expliquez pourquoi elle est appropriée pour ce jeu de données.\n",
        "\n",
        "    - Assurez-vous que cette technique est appliquée uniquement aux données d'entraînement, avec la même transformation appliquée ensuite aux données de test sans nouvel ajustement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cellule de code\n",
        "from sklearn import preprocessing\n",
        "numerical_attributes = ['age', 'bmi', 'HbA1c_level', 'blood_glucose_level']\n",
        "\n",
        "standard = preprocessing.StandardScaler()\n",
        "minMax = preprocessing.MinMaxScaler()\n",
        "maxAbs = preprocessing.MaxAbsScaler()\n",
        "power = preprocessing.PowerTransformer()\n",
        "robust = preprocessing.RobustScaler()\n",
        "\n",
        "# TODO: we choose this scaler because **************\n",
        "scaler = preprocessing.StandardScaler()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_ = scaler.fit_transform(X_train)\n",
        "X_test_ = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Développement et évaluation des modèles\n",
        "\n",
        "7. **Développement des modèles** :\n",
        "\n",
        "    - Implémentez les modèles d'apprentissage automatique abordés en classe : arbres de décision, K-Nearest Neighbors (KNN) et régression logistique. Utilisez les paramètres par défaut de scikit-learn comme base pour entraîner chaque modèle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cellule de code\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "dt_model = DecisionTreeClassifier()\n",
        "knn_model = KNeighborsClassifier()\n",
        "lr_model = LogisticRegression()\n",
        "\n",
        "dt_model.fit(X_train_, y_train_)\n",
        "knn_model.fit(X_train_, y_train_)\n",
        "lr_model.fit(X_train_, y_train_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "8. **Évaluation des modèles** :\n",
        "\n",
        "    - Utilisez la validation croisée pour évaluer chaque modèle, en justifiant votre choix du nombre de plis.\n",
        "\n",
        "    - Évaluez les modèles à l'aide de métriques telles que la précision, le rappel et le score F1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> Since we have a large dataset, we could use k=10 as it would give us low bias and modest variance ([A Gentle Introduction to k-fold Cross-Validation - MachineLearningMastery.com](https://machinelearningmastery.com/k-fold-cross-validation/))  \n",
        "> However, due to computational restrictions, we choose k=5 (which is the default) as it would give us satisfacotry results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cellule de code\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "metrics = (\"precision\", \"recall\", \"accuracy\", \"f1\")\n",
        "\n",
        "for model in [dt_model, knn_model, lr_model]:\n",
        "    print(f\"Model: {type(model).__name__}\")\n",
        "    for metric in metrics:\n",
        "        scores = cross_val_score(model, X_train_, y_train_, scoring=metric, cv=5) \n",
        "        print(f\"{metric}: {scores}\")\n",
        "        print(f\"Mean score: {scores.mean():.3f}\")\n",
        "        print(f\"StandardDeviation: {scores.std():.3f}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optimisation des hyperparamètres\n",
        "\n",
        "9. **Exploration et évaluation des performances :**\n",
        "\n",
        "    - Étudiez l'impact de la variation des valeurs des hyperparamètres sur les performances de chaque modèle.\n",
        "\n",
        "    - Concentrez-vous sur les hyperparamètres pertinents suivants pour chaque modèle :\n",
        "\n",
        "        - [DecisionTreeClassifier](https://scikit-learn.org/dev/modules/generated/sklearn.tree.DecisionTreeClassifier.html) : `criterion` et `max_depth`.\n",
        "  \n",
        "        - [LogisticRegression](https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html) : `penalty`, `max_iter`, et `tol`.\n",
        "  \n",
        "        - [KNeighborsClassifier](https://scikit-learn.org/dev/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) : `n_neighbors` et `weights`.\n",
        "\n",
        "    - Employez une stratégie de recherche en grille ou utilisez les méthodes intégrées de scikit-learn pour évaluer exhaustivement toutes les combinaisons des valeurs d'hyperparamètres. La validation croisée doit être utilisée pour évaluer chaque combinaison.\n",
        "\n",
        "    - Quantifiez les performances de chaque configuration d'hyperparamètres en utilisant des métriques telles que la précision, le rappel et le score F1.\n",
        "\n",
        "    - Affichez les résultats dans un format tabulaire ou graphique (par exemple, graphiques en ligne, diagrammes en barres) pour démontrer efficacement l'influence des variations des hyperparamètres sur les performances du modèle.\n",
        "\n",
        "    - Spécifiez les valeurs par défaut de chaque hyperparamètre testé.\n",
        "\n",
        "    - Analysez les résultats et offrez des perspectives sur les configurations d'hyperparamètres ayant obtenu les meilleures performances pour chaque modèle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cellule de code\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "def grid_search(model, param_grid, X_train_, y_train_, X_test_, y_test_):\n",
        "    grid = GridSearchCV(model, param_grid, cv=5)\n",
        "    grid.fit(X_train_, y_train_)\n",
        "    print(f\"Best hyperparameters: {grid.best_params_}\")\n",
        "    print(f\"Best score: {grid.best_score_}\")\n",
        "        \n",
        "    results = grid.cv_results_\n",
        "    print(f\"Results: {results}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "param_grid_dt = [\n",
        "    {'max_depth': range(1, 10), # default = None\n",
        "   'criterion': [\"gini\", \"entropy\", \"log_loss\"] }, # default = gini\n",
        "]\n",
        "param_grid_kn = [\n",
        "  {'n_neighbors': range(1, 6),  # default = 5\n",
        "   'weights': [\"uniform\", \"distance\"]} # default = uniform\n",
        "]\n",
        "param_grid_lr = [\n",
        "  {'penalty': [\"l1\", \"l2\", \"elasticnet\", \"none\"], # default = l2\n",
        "   'max_iter' : [100, 200, 400, 800, 1600], # default = 100\n",
        "   'tol' : [0.01, 0.001, 0.0001]} # default = 1e-4\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dt_model2 = DecisionTreeClassifier()\n",
        "\n",
        "grid_search(dt_model2, param_grid_dt, X_train_, y_train_, X_test_, y_test_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "knn_model2 = KNeighborsClassifier()\n",
        "\n",
        "grid_search(knn_model2, param_grid_kn, X_train_, y_train_, X_test_, y_test_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lr_model2 = LogisticRegression()\n",
        "\n",
        "grid_search(lr_model2, param_grid_lr, X_train_, y_train_, X_test_, y_test_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analyse des résultats\n",
        "\n",
        "10. **Comparaison des modèles** :\n",
        "\n",
        "    - Comparez les résultats obtenus pour chaque modèle.\n",
        "\n",
        "    - Discutez des différences observées dans les performances des modèles et fournissez des explications potentielles. Considérez des aspects tels que la complexité des modèles, le déséquilibre des données, le surapprentissage et l'impact du réglage des paramètres sur les résultats globaux.\n",
        "\n",
        "    - Fournissez des recommandations sur le(s) modèle(s) à choisir pour cette tâche et justifiez vos choix en fonction des résultats de l'analyse.\n",
        "\n",
        "    - Entraînez le(s) modèle(s) recommandé(s) en utilisant les valeurs optimales des paramètres identifiés lors de l'optimisation des paramètres. Appliquez ensuite le modèle entraîné aux données de test. Documentez vos observations de manière détaillée. Évaluez spécifiquement si les résultats dérivés de la validation croisée sont cohérents avec ceux obtenus sur le jeu de test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cellule de code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Documentation de l'analyse exploratoire\n",
        "\n",
        "Le rapport doit documenter de manière complète le processus suivi pendant ce devoir. Le notebook Jupyter doit inclure les éléments suivants :\n",
        "\n",
        "- Votre nom(s), numéro(s) d'étudiant.e.s et un titre de rapport.\n",
        "- Expliquez comment les tâches ont été réparties entre les membres. Comment avez-vous fait en sorte que les deux personnes atteignent les objectifs d'apprentissage ?\n",
        "- Une section pour chaque étape de l'analyse exploratoire, contenant le code Python pertinent et les explications ou résultats.\n",
        "  - Pour les sections nécessitant du code Python, incluez le code dans une cellule.\n",
        "  - Pour les sections nécessitant des explications ou des résultats, incluez-les dans une cellule distincte ou en combinaison avec les cellules de code.\n",
        "- Assurez une séparation logique du code dans différentes cellules. Par exemple, la définition d'une fonction doit se trouver dans une cellule et son exécution dans une autre. Évitez de placer trop de code dans une seule cellule pour maintenir la clarté et la lisibilité.\n",
        "- Le notebook que vous soumettez doit inclure les résultats de l'exécution, y compris les graphiques, en veillant à ce que l'assistant d'enseignement puisse évaluer le notebook sans avoir à exécuter le code.\n",
        "\n",
        "# Ressources\n",
        "\n",
        "- [Guide to Scaling and Standardizing](https://www.kaggle.com/code/discdiver/guide-to-scaling-and-standardizing/notebook)\n",
        "- [Compare the effect of different scalers on data with outliers — scikit-learn 1.5.2 documentation](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html)\n",
        "- [One Hot Encoding in Machine Learning - GeeksforGeeks](https://www.geeksforgeeks.org/ml-one-hot-encoding/)\n",
        "- [A Gentle Introduction to k-fold Cross-Validation - MachineLearningMastery.com](https://machinelearningmastery.com/k-fold-cross-validation/)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
