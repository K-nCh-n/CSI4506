{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**CSI 4106 Introduction to Artificial Intelligence** <br/>\n",
        "*Assignment 3: Neural Networks*\n",
        "\n",
        "# Identification\n",
        "\n",
        "Name: Ken Chan Thim <br/>\n",
        "Student Number: 300208086\n",
        "\n",
        "Name: <br/>\n",
        "Student Number:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Code cell\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Analyse exploratoire\n",
        "\n",
        "### Chargement de l'ensemble de données\n",
        "\n",
        "Un ensemble de données a été créé pour ce devoir. Il est disponible sur un dépôt GitHub public :\n",
        "\n",
        "- [github.com/turcotte/csi4106-f24/tree/main/assignments-data/a3](https://github.com/turcotte/csi4106-f24/tree/main/assignments-data/a3)\n",
        "\n",
        "Vous devez accéder à l'ensemble de données et le lire directement à partir de ce dépôt GitHub dans votre notebook Jupyter.\n",
        "\n",
        "Utilisez cette cellule de code pour vos directives `import` et autres initialisations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Code cell\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. **Charger l'ensemble de données** :\n",
        "\n",
        "    - Écrivez du code pour charger les trois ensembles de données.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>453</th>\n",
              "      <th>454</th>\n",
              "      <th>455</th>\n",
              "      <th>456</th>\n",
              "      <th>457</th>\n",
              "      <th>458</th>\n",
              "      <th>459</th>\n",
              "      <th>460</th>\n",
              "      <th>461</th>\n",
              "      <th>462</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0556</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0556</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0556</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.1667</td>\n",
              "      <td>0.2222</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.1667</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.1905</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.3333</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2857</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.1905</td>\n",
              "      <td>0.381</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0225</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0112</td>\n",
              "      <td>0.1348</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0112</td>\n",
              "      <td>0.1348</td>\n",
              "      <td>0.0112</td>\n",
              "      <td>0.1685</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0787</td>\n",
              "      <td>0.0674</td>\n",
              "      <td>0.0112</td>\n",
              "      <td>0.0225</td>\n",
              "      <td>0.1573</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0225</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.6667</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 463 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0       1       2       3       4       5       6       7       8    \\\n",
              "0    2  0.0000  0.0556  0.0000  0.0556  0.1111  0.0000  0.0556  0.0000   \n",
              "1    2  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
              "2    2  0.1905  0.0000  0.3333  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
              "3    2  0.0225  0.0000  0.0112  0.1348  0.0000  0.0112  0.1348  0.0112   \n",
              "4    2  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
              "\n",
              "      9    ...     453     454     455     456     457     458  459     460  \\\n",
              "0  0.0000  ...  0.1667  0.2222  0.0000  0.0000  0.1667  0.0000  0.0  0.0000   \n",
              "1  0.0000  ...  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0  0.0000   \n",
              "2  0.2857  ...  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0  0.1905   \n",
              "3  0.1685  ...  0.0000  0.0787  0.0674  0.0112  0.0225  0.1573  0.0  0.0225   \n",
              "4  0.0000  ...  0.0000  0.0000  0.0000  0.6667  0.0000  0.0000  0.0  0.0000   \n",
              "\n",
              "     461  462  \n",
              "0  0.000  0.0  \n",
              "1  0.000  0.0  \n",
              "2  0.381  0.0  \n",
              "3  0.000  0.0  \n",
              "4  0.000  0.0  \n",
              "\n",
              "[5 rows x 463 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Code cell\n",
        "df_train = pd.read_csv(\"https://raw.githubusercontent.com/turcotte/csi4106-f24/refs/heads/main/assignments-data/a3/cb513_train.csv\", header=None)\n",
        "df_test = pd.read_csv(\"https://raw.githubusercontent.com/turcotte/csi4106-f24/refs/heads/main/assignments-data/a3/cb513_test.csv\", header=None)\n",
        "df_valid = pd.read_csv(\"https://raw.githubusercontent.com/turcotte/csi4106-f24/refs/heads/main/assignments-data/a3/cb513_valid.csv\", header=None)\n",
        "\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 58291 entries, 0 to 58290\n",
            "Columns: 463 entries, 0 to 462\n",
            "dtypes: float64(462), int64(1)\n",
            "memory usage: 205.9 MB\n"
          ]
        }
      ],
      "source": [
        "df_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>453</th>\n",
              "      <th>454</th>\n",
              "      <th>455</th>\n",
              "      <th>456</th>\n",
              "      <th>457</th>\n",
              "      <th>458</th>\n",
              "      <th>459</th>\n",
              "      <th>460</th>\n",
              "      <th>461</th>\n",
              "      <th>462</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>58291.000000</td>\n",
              "      <td>58291.000000</td>\n",
              "      <td>58291.000000</td>\n",
              "      <td>58291.000000</td>\n",
              "      <td>58291.000000</td>\n",
              "      <td>58291.000000</td>\n",
              "      <td>58291.000000</td>\n",
              "      <td>58291.000000</td>\n",
              "      <td>58291.000000</td>\n",
              "      <td>58291.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>58291.000000</td>\n",
              "      <td>58291.000000</td>\n",
              "      <td>58291.000000</td>\n",
              "      <td>58291.000000</td>\n",
              "      <td>58291.000000</td>\n",
              "      <td>58291.000000</td>\n",
              "      <td>58291.000000</td>\n",
              "      <td>58291.000000</td>\n",
              "      <td>58291.000000</td>\n",
              "      <td>58291.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.040349</td>\n",
              "      <td>0.081129</td>\n",
              "      <td>0.015958</td>\n",
              "      <td>0.056881</td>\n",
              "      <td>0.058845</td>\n",
              "      <td>0.039120</td>\n",
              "      <td>0.075578</td>\n",
              "      <td>0.022290</td>\n",
              "      <td>0.055313</td>\n",
              "      <td>0.054573</td>\n",
              "      <td>...</td>\n",
              "      <td>0.043422</td>\n",
              "      <td>0.034924</td>\n",
              "      <td>0.045785</td>\n",
              "      <td>0.059653</td>\n",
              "      <td>0.055848</td>\n",
              "      <td>0.067431</td>\n",
              "      <td>0.014030</td>\n",
              "      <td>0.034971</td>\n",
              "      <td>0.034169</td>\n",
              "      <td>0.000491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.883748</td>\n",
              "      <td>0.170770</td>\n",
              "      <td>0.095076</td>\n",
              "      <td>0.154762</td>\n",
              "      <td>0.146985</td>\n",
              "      <td>0.133049</td>\n",
              "      <td>0.201984</td>\n",
              "      <td>0.096272</td>\n",
              "      <td>0.141717</td>\n",
              "      <td>0.135915</td>\n",
              "      <td>...</td>\n",
              "      <td>0.148612</td>\n",
              "      <td>0.105381</td>\n",
              "      <td>0.134625</td>\n",
              "      <td>0.142328</td>\n",
              "      <td>0.142496</td>\n",
              "      <td>0.156227</td>\n",
              "      <td>0.088168</td>\n",
              "      <td>0.126633</td>\n",
              "      <td>0.114237</td>\n",
              "      <td>0.013854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.083300</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.033300</td>\n",
              "      <td>0.047600</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.031200</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.037000</td>\n",
              "      <td>0.047600</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.024400</td>\n",
              "      <td>0.025600</td>\n",
              "      <td>0.055650</td>\n",
              "      <td>0.047600</td>\n",
              "      <td>0.055600</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.988800</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 463 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                0             1             2             3             4    \\\n",
              "count  58291.000000  58291.000000  58291.000000  58291.000000  58291.000000   \n",
              "mean       1.040349      0.081129      0.015958      0.056881      0.058845   \n",
              "std        0.883748      0.170770      0.095076      0.154762      0.146985   \n",
              "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "50%        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "75%        2.000000      0.083300      0.000000      0.033300      0.047600   \n",
              "max        2.000000      1.000000      1.000000      1.000000      1.000000   \n",
              "\n",
              "                5             6             7             8             9    \\\n",
              "count  58291.000000  58291.000000  58291.000000  58291.000000  58291.000000   \n",
              "mean       0.039120      0.075578      0.022290      0.055313      0.054573   \n",
              "std        0.133049      0.201984      0.096272      0.141717      0.135915   \n",
              "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "75%        0.000000      0.031200      0.000000      0.037000      0.047600   \n",
              "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
              "\n",
              "       ...           453           454           455           456  \\\n",
              "count  ...  58291.000000  58291.000000  58291.000000  58291.000000   \n",
              "mean   ...      0.043422      0.034924      0.045785      0.059653   \n",
              "std    ...      0.148612      0.105381      0.134625      0.142328   \n",
              "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
              "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
              "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
              "75%    ...      0.000000      0.024400      0.025600      0.055650   \n",
              "max    ...      1.000000      1.000000      1.000000      1.000000   \n",
              "\n",
              "                457           458           459           460           461  \\\n",
              "count  58291.000000  58291.000000  58291.000000  58291.000000  58291.000000   \n",
              "mean       0.055848      0.067431      0.014030      0.034971      0.034169   \n",
              "std        0.142496      0.156227      0.088168      0.126633      0.114237   \n",
              "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "75%        0.047600      0.055600      0.000000      0.000000      0.000000   \n",
              "max        1.000000      1.000000      1.000000      1.000000      0.988800   \n",
              "\n",
              "                462  \n",
              "count  58291.000000  \n",
              "mean       0.000491  \n",
              "std        0.013854  \n",
              "min        0.000000  \n",
              "25%        0.000000  \n",
              "50%        0.000000  \n",
              "75%        0.000000  \n",
              "max        0.500000  \n",
              "\n",
              "[8 rows x 463 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prétraitement des données\n",
        "\n",
        "2. **Brasser les lignes** :\n",
        "\n",
        "    - Étant donné que les exemples sont générés en faisant glisser une fenêtre sur chaque séquence de protéines, la plupart des exemples adjacents proviennent de la même protéine et partagent 20 positions. Pour atténuer l'impact potentiel négatif sur l'entraînement du modèle, la première étape consiste à brasser (*shuffle*) les **lignes** de la matrice de données.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After shuffling: \n",
            "   0       1    2       3       4       5       6       7       8       9    \\\n",
            "0    2  0.6786  0.0  0.0000  0.0000  0.0000  0.2500  0.0000  0.0000  0.0000   \n",
            "1    0  0.0598  0.0  0.0217  0.0326  0.0598  0.5109  0.0054  0.0109  0.0217   \n",
            "2    1  0.0000  0.0  0.7273  0.0000  0.0000  0.0000  0.0000  0.0000  0.0303   \n",
            "3    2  0.3750  0.0  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
            "4    0  0.0000  0.0  0.0000  0.0000  0.1458  0.0208  0.0000  0.3750  0.0000   \n",
            "\n",
            "   ...     453     454     455     456     457     458  459    460     461  \\\n",
            "0  ...  0.1071  0.0357  0.0000  0.3929  0.0714  0.0357  0.0  0.000  0.0000   \n",
            "1  ...  0.0489  0.0054  0.0109  0.2826  0.0598  0.0000  0.0  0.000  0.0000   \n",
            "2  ...  0.0606  0.1818  0.0303  0.0303  0.0909  0.0606  0.0  0.000  0.0909   \n",
            "3  ...  0.0000  0.0000  0.8750  0.0000  0.0000  0.0000  0.0  0.000  0.0000   \n",
            "4  ...  0.0208  0.0000  0.0625  0.1458  0.2083  0.0000  0.0  0.125  0.0208   \n",
            "\n",
            "   462  \n",
            "0  0.0  \n",
            "1  0.0  \n",
            "2  0.0  \n",
            "3  0.0  \n",
            "4  0.0  \n",
            "\n",
            "[5 rows x 463 columns]\n"
          ]
        }
      ],
      "source": [
        "# Code cell\n",
        "\n",
        "# https://stackoverflow.com/questions/29576430/shuffle-dataframe-rows\n",
        "df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
        "df_test = df_test.sample(frac=1).reset_index(drop=True)\n",
        "df_valid = df_valid.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "print(f\"After shuffling: \\n{df_train.head()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. **Mise à l'échelle des caractéristiques numériques** :\n",
        "\n",
        "    - Étant donné que les 462 caractéristiques sont des proportions représentées par des valeurs comprises entre 0 et 1, la mise à l'échelle peut ne pas être nécessaire. Dans nos évaluations, l'utilisation de [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) a en fait dégradé les performances du modèle. Dans votre flux de traitement, comparez les effets de ne pas mettre à l'échelle les données par rapport à l'application de [MinMaxScaler](https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.MinMaxScaler.html). Par souci de temps, une seule expérience suffira. Il est important de noter que lorsque la mise à l'échelle est appliquée, une méthode uniforme doit être utilisée pour toutes les colonnes, compte tenu de leur nature homogène."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>453</th>\n",
              "      <th>454</th>\n",
              "      <th>455</th>\n",
              "      <th>456</th>\n",
              "      <th>457</th>\n",
              "      <th>458</th>\n",
              "      <th>459</th>\n",
              "      <th>460</th>\n",
              "      <th>461</th>\n",
              "      <th>462</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.6786</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2500</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.1071</td>\n",
              "      <td>0.0357</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.3929</td>\n",
              "      <td>0.0714</td>\n",
              "      <td>0.0357</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0598</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0217</td>\n",
              "      <td>0.0326</td>\n",
              "      <td>0.0598</td>\n",
              "      <td>0.5109</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0109</td>\n",
              "      <td>0.0217</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0489</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0109</td>\n",
              "      <td>0.2826</td>\n",
              "      <td>0.0598</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.7273</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0303</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0606</td>\n",
              "      <td>0.1818</td>\n",
              "      <td>0.0303</td>\n",
              "      <td>0.0303</td>\n",
              "      <td>0.0909</td>\n",
              "      <td>0.0606</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.091930</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.3750</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.8750</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.1458</td>\n",
              "      <td>0.0208</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.3750</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.1042</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0208</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>0.1458</td>\n",
              "      <td>0.2083</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.021036</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 462 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      1    2       3       4       5       6       7       8       9    \\\n",
              "0  0.6786  0.0  0.0000  0.0000  0.0000  0.2500  0.0000  0.0000  0.0000   \n",
              "1  0.0598  0.0  0.0217  0.0326  0.0598  0.5109  0.0054  0.0109  0.0217   \n",
              "2  0.0000  0.0  0.7273  0.0000  0.0000  0.0000  0.0000  0.0000  0.0303   \n",
              "3  0.3750  0.0  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
              "4  0.0000  0.0  0.0000  0.0000  0.1458  0.0208  0.0000  0.3750  0.0000   \n",
              "\n",
              "      10   ...     453     454     455     456     457     458  459    460  \\\n",
              "0  0.0000  ...  0.1071  0.0357  0.0000  0.3929  0.0714  0.0357  0.0  0.000   \n",
              "1  0.0000  ...  0.0489  0.0054  0.0109  0.2826  0.0598  0.0000  0.0  0.000   \n",
              "2  0.0000  ...  0.0606  0.1818  0.0303  0.0303  0.0909  0.0606  0.0  0.000   \n",
              "3  0.0000  ...  0.0000  0.0000  0.8750  0.0000  0.0000  0.0000  0.0  0.000   \n",
              "4  0.1042  ...  0.0208  0.0000  0.0625  0.1458  0.2083  0.0000  0.0  0.125   \n",
              "\n",
              "        461  462  \n",
              "0  0.000000  0.0  \n",
              "1  0.000000  0.0  \n",
              "2  0.091930  0.0  \n",
              "3  0.000000  0.0  \n",
              "4  0.021036  0.0  \n",
              "\n",
              "[5 rows x 462 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# apply scaler to features but not target\n",
        "df_train_scaled = pd.DataFrame(scaler.fit_transform(df_train.iloc[:, 1:]), columns=df_train.columns[1:])\n",
        "df_test_scaled = pd.DataFrame(scaler.transform(df_test.iloc[:, 1:]), columns=df_test.columns[1:])\n",
        "df_valid_scaled = pd.DataFrame(scaler.transform(df_valid.iloc[:, 1:]), columns=df_valid.columns[1:])\n",
        "\n",
        "df_train_scaled.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> ## Findings of 3. Mise à l'échelle des caractéristiques numériques\n",
        ">\n",
        "> As we can see from the results in [5. Développement et évaluation des modèles](#développement-et-évaluation-des-modèles), there are minimal differences between using the unscaled data and data that was scaled using MinMaxScaler. This makes sense because of the way MinMaxScaler works because the feature values are already between 0 and 1, and MinMaxScaler works by scaling the feature values between 0 and 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. **Séparation des cibles et des données** :\n",
        "\n",
        "    - Dans les fichiers CSV, les cibles et les données sont combinées. Pour préparer nos expériences d'apprentissage automatique, séparez les données d'entraînement $X$ et le vecteur cible $y$ pour chacun des trois ensembles de données."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Code cell\n",
        "\n",
        "X_train_scaled, y_train = df_train_scaled, df_train.iloc[:, 0]\n",
        "X_test_scaled, y_test = df_test_scaled, df_test.iloc[:, 0]\n",
        "X_valid_scaled, y_valid = df_valid_scaled, df_valid.iloc[:, 0]\n",
        "\n",
        "X_train_unscaled = df_train.iloc[:, 1:]\n",
        "X_test_unscaled = df_test.iloc[:, 1:]\n",
        "X_valid_unscaled = df_valid.iloc[:, 1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>453</th>\n",
              "      <th>454</th>\n",
              "      <th>455</th>\n",
              "      <th>456</th>\n",
              "      <th>457</th>\n",
              "      <th>458</th>\n",
              "      <th>459</th>\n",
              "      <th>460</th>\n",
              "      <th>461</th>\n",
              "      <th>462</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.6786</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2500</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.1071</td>\n",
              "      <td>0.0357</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.3929</td>\n",
              "      <td>0.0714</td>\n",
              "      <td>0.0357</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0598</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0217</td>\n",
              "      <td>0.0326</td>\n",
              "      <td>0.0598</td>\n",
              "      <td>0.5109</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0109</td>\n",
              "      <td>0.0217</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0489</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0109</td>\n",
              "      <td>0.2826</td>\n",
              "      <td>0.0598</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.7273</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0303</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0606</td>\n",
              "      <td>0.1818</td>\n",
              "      <td>0.0303</td>\n",
              "      <td>0.0303</td>\n",
              "      <td>0.0909</td>\n",
              "      <td>0.0606</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.091930</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.3750</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.8750</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.1458</td>\n",
              "      <td>0.0208</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.3750</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.1042</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0208</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0625</td>\n",
              "      <td>0.1458</td>\n",
              "      <td>0.2083</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.125</td>\n",
              "      <td>0.021036</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 462 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      1    2       3       4       5       6       7       8       9    \\\n",
              "0  0.6786  0.0  0.0000  0.0000  0.0000  0.2500  0.0000  0.0000  0.0000   \n",
              "1  0.0598  0.0  0.0217  0.0326  0.0598  0.5109  0.0054  0.0109  0.0217   \n",
              "2  0.0000  0.0  0.7273  0.0000  0.0000  0.0000  0.0000  0.0000  0.0303   \n",
              "3  0.3750  0.0  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
              "4  0.0000  0.0  0.0000  0.0000  0.1458  0.0208  0.0000  0.3750  0.0000   \n",
              "\n",
              "      10   ...     453     454     455     456     457     458  459    460  \\\n",
              "0  0.0000  ...  0.1071  0.0357  0.0000  0.3929  0.0714  0.0357  0.0  0.000   \n",
              "1  0.0000  ...  0.0489  0.0054  0.0109  0.2826  0.0598  0.0000  0.0  0.000   \n",
              "2  0.0000  ...  0.0606  0.1818  0.0303  0.0303  0.0909  0.0606  0.0  0.000   \n",
              "3  0.0000  ...  0.0000  0.0000  0.8750  0.0000  0.0000  0.0000  0.0  0.000   \n",
              "4  0.1042  ...  0.0208  0.0000  0.0625  0.1458  0.2083  0.0000  0.0  0.125   \n",
              "\n",
              "        461  462  \n",
              "0  0.000000  0.0  \n",
              "1  0.000000  0.0  \n",
              "2  0.091930  0.0  \n",
              "3  0.000000  0.0  \n",
              "4  0.021036  0.0  \n",
              "\n",
              "[5 rows x 462 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_scaled.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    2\n",
              "1    0\n",
              "2    1\n",
              "3    2\n",
              "4    0\n",
              "Name: 0, dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0\n",
              "2    23986\n",
              "0    21634\n",
              "1    12671\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Développement et évaluation des modèles\n",
        "\n",
        "5. **Développement de modèle** :\n",
        "\n",
        "    - **Modèle de base** : Implémentez un modèle utilisant le [DummyClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html). Ce modèle ignore les données d'entrée et prédit la classe majoritaire. Un tel modèle est parfois appelé modèle « homme de paille ».\n",
        "\n",
        "    - **Modèle de référence** : Comme modèle de référence, sélectionnez un des algorithmes d'apprentissage automatique précédemment étudiés : arbres de décision, k-plus proches voisins (KNN) ou régression logistique. Utilisez les paramètres par défaut fournis par scikit-learn pour entraîner chaque modèle en tant que modèle de référence. Pourquoi avez-vous choisi ce classificateur particulier ? Pourquoi pensez-vous qu'il soit approprié pour cette tâche spécifique ?\n",
        "\n",
        "    - **Modèle de réseau de neurones** : En utilisant [Keras](https://keras.io) et [TensorFlow](https://www.tensorflow.org), construisez un modèle séquentiel comprenant une couche d'entrée, une couche cachée et une couche de sortie. La couche d'entrée doit comporter 462 nœuds, correspondant aux 462 attributs de chaque exemple. La couche cachée doit comprendre 8 nœuds et utiliser la fonction d'activation par défaut. La couche de sortie doit comporter trois nœuds, correspondant aux trois classes : hélice (0), feuillet (1) et enroulement (2). Appliquez la fonction d'activation softmax à la couche de sortie pour que les sorties soient traitées comme des probabilités, avec leur somme égale à 1 pour chaque exemple d'entraînement.\n",
        "\n",
        "    Nous avons donc trois modèles : de base, de référence et réseau de neurones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.41989472263463357"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Code cell\n",
        "\n",
        "# Dummy classifier\n",
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
        "dummy_clf.fit(X_train_scaled, y_train)\n",
        "dummy_clf.score(X_valid_scaled, y_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> ## Reference model\n",
        "> \n",
        "> We choose the reference model to be a Decision Tree because ############"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score without scaling: 0.5002024564718586\n",
            "Score with scaling: 0.5015521662842489\n"
          ]
        }
      ],
      "source": [
        "# Decision tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "dt_clf.fit(X_train_unscaled, y_train)\n",
        "dt_score = dt_clf.score(X_valid_unscaled, y_valid)\n",
        "\n",
        "dt_clf_scaled = DecisionTreeClassifier(max_depth=3, min_samples_leaf=10)\n",
        "dt_clf_scaled.fit(X_train_scaled, y_train)\n",
        "dt_scaled_score = dt_clf_scaled.score(X_valid_scaled, y_valid)\n",
        "\n",
        "print(f\"Score without scaling: {dt_score}\")\n",
        "print(f\"Score with scaling: {dt_scaled_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score without scaling: 0.4289377783776488\n",
            "Score with scaling: 0.4273181266027804\n"
          ]
        }
      ],
      "source": [
        "# KNN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn_clf = KNeighborsClassifier()\n",
        "knn_clf.fit(X_train_unscaled, y_train)\n",
        "knn_score = knn_clf.score(X_valid_unscaled, y_valid)\n",
        "\n",
        "knn_clf_scaled = KNeighborsClassifier()\n",
        "knn_clf_scaled.fit(X_train_scaled, y_train)\n",
        "knn_scaled_score = knn_clf_scaled.score(X_valid_scaled, y_valid)\n",
        "\n",
        "print(f\"Score without scaling: {knn_score}\")\n",
        "print(f\"Score with scaling: {knn_scaled_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score without scaling: 0.6720205155891483\n",
            "Score with scaling: 0.6731002834390606\n"
          ]
        }
      ],
      "source": [
        "# Logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr_clf = LogisticRegression()\n",
        "lr_clf.fit(X_train_unscaled, y_train)\n",
        "lr_score = lr_clf.score(X_valid_unscaled, y_valid)\n",
        "\n",
        "lr_clf_scaled = LogisticRegression()\n",
        "lr_clf_scaled.fit(X_train_scaled, y_train)\n",
        "lr_scaled_score = lr_clf_scaled.score(X_valid_scaled, y_valid)\n",
        "\n",
        "print(f\"Score without scaling: {lr_score}\")\n",
        "print(f\"Score with scaling: {lr_scaled_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-11-10 13:49:45.451570: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-11-10 13:49:45.523058: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-11-10 13:49:45.605298: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1731264585.686031   45817 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1731264585.709715   45817 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-10 13:49:45.915358: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/home/kc/dev/2249/CSI4506/Devoir3/venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "W0000 00:00:1731264588.322825   45817 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">462</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">213,906</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,704</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m462\u001b[0m)            │       \u001b[38;5;34m213,906\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m3,704\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m27\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">217,637</span> (850.14 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m217,637\u001b[0m (850.14 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">217,637</span> (850.14 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m217,637\u001b[0m (850.14 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Keras and tensorflow\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "keras_model_scaled = tf.keras.Sequential()\n",
        "\n",
        "keras_model_scaled.add(tf.keras.layers.Dense(462, input_dim=462, activation='relu'))\n",
        "keras_model_scaled.add(tf.keras.layers.Dense(8))\n",
        "keras_model_scaled.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
        "\n",
        "keras_model_scaled.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4811 - loss: 1.0264 - val_accuracy: 0.6233 - val_loss: 0.8694\n",
            "Epoch 2/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6581 - loss: 0.8045 - val_accuracy: 0.6632 - val_loss: 0.7797\n",
            "Epoch 3/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6851 - loss: 0.7432 - val_accuracy: 0.6689 - val_loss: 0.7698\n",
            "Epoch 4/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6927 - loss: 0.7300 - val_accuracy: 0.6704 - val_loss: 0.7663\n",
            "Epoch 5/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 472us/step - accuracy: 0.6955 - loss: 0.7223 - val_accuracy: 0.6711 - val_loss: 0.7636\n",
            "Epoch 6/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6990 - loss: 0.7153 - val_accuracy: 0.6724 - val_loss: 0.7611\n",
            "Epoch 7/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7025 - loss: 0.7078 - val_accuracy: 0.6730 - val_loss: 0.7582\n",
            "Epoch 8/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7067 - loss: 0.6992 - val_accuracy: 0.6749 - val_loss: 0.7547\n",
            "Epoch 9/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7118 - loss: 0.6891 - val_accuracy: 0.6786 - val_loss: 0.7504\n",
            "Epoch 10/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7179 - loss: 0.6769 - val_accuracy: 0.6807 - val_loss: 0.7452\n",
            "Epoch 11/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7259 - loss: 0.6622 - val_accuracy: 0.6840 - val_loss: 0.7389\n",
            "Epoch 12/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7349 - loss: 0.6445 - val_accuracy: 0.6886 - val_loss: 0.7319\n",
            "Epoch 13/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7442 - loss: 0.6240 - val_accuracy: 0.6923 - val_loss: 0.7256\n",
            "Epoch 14/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7553 - loss: 0.6014 - val_accuracy: 0.6944 - val_loss: 0.7211\n",
            "Epoch 15/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7663 - loss: 0.5779 - val_accuracy: 0.6947 - val_loss: 0.7193\n",
            "Epoch 16/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 966us/step - accuracy: 0.7775 - loss: 0.5538 - val_accuracy: 0.6947 - val_loss: 0.7205\n",
            "Epoch 17/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7884 - loss: 0.5292 - val_accuracy: 0.6938 - val_loss: 0.7248\n",
            "Epoch 18/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8007 - loss: 0.5040 - val_accuracy: 0.6925 - val_loss: 0.7317\n",
            "Epoch 19/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8125 - loss: 0.4781 - val_accuracy: 0.6921 - val_loss: 0.7420\n",
            "Epoch 20/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8258 - loss: 0.4516 - val_accuracy: 0.6906 - val_loss: 0.7551\n",
            "Epoch 21/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8397 - loss: 0.4244 - val_accuracy: 0.6857 - val_loss: 0.7725\n",
            "Epoch 22/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8519 - loss: 0.3969 - val_accuracy: 0.6821 - val_loss: 0.7921\n",
            "Epoch 23/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8653 - loss: 0.3692 - val_accuracy: 0.6797 - val_loss: 0.8136\n",
            "Epoch 24/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8785 - loss: 0.3415 - val_accuracy: 0.6786 - val_loss: 0.8383\n",
            "Epoch 25/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8914 - loss: 0.3141 - val_accuracy: 0.6753 - val_loss: 0.8655\n",
            "Epoch 26/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 464us/step - accuracy: 0.9034 - loss: 0.2872 - val_accuracy: 0.6719 - val_loss: 0.8948\n",
            "Epoch 27/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9163 - loss: 0.2609 - val_accuracy: 0.6684 - val_loss: 0.9255\n",
            "Epoch 28/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9279 - loss: 0.2354 - val_accuracy: 0.6643 - val_loss: 0.9581\n",
            "Epoch 29/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9389 - loss: 0.2112 - val_accuracy: 0.6628 - val_loss: 0.9937\n",
            "Epoch 30/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9476 - loss: 0.1881 - val_accuracy: 0.6626 - val_loss: 1.0308\n",
            "Epoch 31/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9567 - loss: 0.1664 - val_accuracy: 0.6605 - val_loss: 1.0700\n",
            "Epoch 32/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9633 - loss: 0.1463 - val_accuracy: 0.6591 - val_loss: 1.1095\n",
            "Epoch 33/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9705 - loss: 0.1281 - val_accuracy: 0.6584 - val_loss: 1.1489\n",
            "Epoch 34/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9768 - loss: 0.1116 - val_accuracy: 0.6577 - val_loss: 1.1879\n",
            "Epoch 35/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9828 - loss: 0.0968 - val_accuracy: 0.6562 - val_loss: 1.2282\n",
            "Epoch 36/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - accuracy: 0.9868 - loss: 0.0839 - val_accuracy: 0.6566 - val_loss: 1.2677\n",
            "Epoch 37/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9904 - loss: 0.0727 - val_accuracy: 0.6561 - val_loss: 1.3063\n",
            "Epoch 38/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9921 - loss: 0.0631 - val_accuracy: 0.6554 - val_loss: 1.3431\n",
            "Epoch 39/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9941 - loss: 0.0549 - val_accuracy: 0.6554 - val_loss: 1.3774\n",
            "Epoch 40/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9961 - loss: 0.0479 - val_accuracy: 0.6564 - val_loss: 1.4096\n"
          ]
        }
      ],
      "source": [
        "keras_model_scaled.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
        "history = keras_model_scaled.fit(X_train_scaled, y_train, validation_data=(X_valid_scaled, y_valid), epochs=40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pd.DataFrame(history.history).plot(\n",
        "    grid=True, figsize=(10, 7), title=\"Loss and Accuracy\", style=\"--.\", ylim=(0, 2)\n",
        ")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "6. **Évaluation des modèles** :\n",
        "\n",
        "    - Utilisez la validation croisée pour évaluer les performances du modèle de référence. Sélectionnez un petit nombre de plis (*plis*) pour éviter des temps de calcul excessives.\n",
        "\n",
        "    - **L'entraînement des réseaux de neurones peut être long.** Par conséquent, leurs performances sont généralement évaluées une seule fois en utilisant un ensemble de validation. Assurez-vous de ne pas utiliser l'ensemble de test avant la fin du devoir.\n",
        "\n",
        "    - Évaluez les modèles en utilisant des métriques telles que la précision, le rappel et le score F1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Code cell\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "def cross_eval_models(model_dict, X_train_, y_train_):\n",
        "    model_scores = {}\n",
        "    metrics = {\n",
        "            \"precision\": make_scorer(precision_score, average='weighted', zero_division=0),\n",
        "            \"recall\": make_scorer(recall_score, average='weighted'),\n",
        "            \"accuracy\": make_scorer(accuracy_score),\n",
        "            \"f1\": make_scorer(f1_score, average='weighted')\n",
        "        }\n",
        "    strat_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    for name, model in model_dict.items():\n",
        "        print(f\"Model: {name}\")\n",
        "        model_scores[name] = {}\n",
        "        for metric_name, scorer in metrics.items():\n",
        "            scores = cross_val_score(model, X_train_, y_train_, scoring=scorer, cv=strat_kfold, n_jobs=-1) \n",
        "            print(f\"{metric_name}: {scores}\")\n",
        "            print(f\"Mean {metric_name}: {scores.mean():.3f}\")\n",
        "            print(f\"StandardDeviation: {scores.std():.3f}\")\n",
        "            model_scores[name][metric_name] = {\"scores\": scores, \"mean\": scores.mean(), \"std\": scores.std()}\n",
        "        print()\n",
        "    return model_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: dummy\n",
            "precision: [0.16935495 0.1693134  0.1693134  0.1693134  0.1693134 ]\n",
            "Mean precision: 0.169\n",
            "StandardDeviation: 0.000\n",
            "recall: [0.41152758 0.4114771  0.4114771  0.4114771  0.4114771 ]\n",
            "Mean recall: 0.411\n",
            "StandardDeviation: 0.000\n",
            "accuracy: [0.41152758 0.4114771  0.4114771  0.4114771  0.4114771 ]\n",
            "Mean accuracy: 0.411\n",
            "StandardDeviation: 0.000\n",
            "f1: [0.23995981 0.23990953 0.23990953 0.23990953 0.23990953]\n",
            "Mean f1: 0.240\n",
            "StandardDeviation: 0.000\n",
            "\n",
            "Model: dt\n",
            "precision: [0.42131046 0.42182486 0.42181508 0.42520285 0.42017455]\n",
            "Mean precision: 0.422\n",
            "StandardDeviation: 0.002\n",
            "recall: [0.5061326  0.50926402 0.51192314 0.51158003 0.50540401]\n",
            "Mean recall: 0.509\n",
            "StandardDeviation: 0.003\n",
            "accuracy: [0.5061326  0.50926402 0.51192314 0.51158003 0.50540401]\n",
            "Mean accuracy: 0.509\n",
            "StandardDeviation: 0.003\n",
            "f1: [0.44479556 0.44667116 0.44979898 0.44883955 0.44373022]\n",
            "Mean f1: 0.447\n",
            "StandardDeviation: 0.002\n",
            "\n",
            "Model: knn\n",
            "precision: [0.49741901 0.48267179 0.49114429 0.49487143 0.49702668]\n",
            "Mean precision: 0.493\n",
            "StandardDeviation: 0.005\n",
            "recall: [0.46950853 0.45067765 0.46929147 0.46628924 0.46577458]\n",
            "Mean recall: 0.464\n",
            "StandardDeviation: 0.007\n",
            "accuracy: [0.46950853 0.45067765 0.46929147 0.46628924 0.46577458]\n",
            "Mean accuracy: 0.464\n",
            "StandardDeviation: 0.007\n",
            "f1: [0.4319518  0.40315463 0.43574571 0.42788241 0.42496874]\n",
            "Mean f1: 0.425\n",
            "StandardDeviation: 0.011\n",
            "\n",
            "Model: lr\n",
            "precision: [0.68544106 0.68426665 0.68080432 0.69212658 0.67592472]\n",
            "Mean precision: 0.684\n",
            "StandardDeviation: 0.005\n",
            "recall: [0.68779484 0.6860525  0.68322182 0.69445874 0.67850403]\n",
            "Mean recall: 0.686\n",
            "StandardDeviation: 0.005\n",
            "accuracy: [0.68779484 0.6860525  0.68322182 0.69445874 0.67850403]\n",
            "Mean accuracy: 0.686\n",
            "StandardDeviation: 0.005\n",
            "f1: [0.68460434 0.6828205  0.67987382 0.6910452  0.67530202]\n",
            "Mean f1: 0.683\n",
            "StandardDeviation: 0.005\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_dict = {\"dummy\": dummy_clf, \"dt\": dt_clf_scaled, \"knn\": knn_clf, \"lr\": lr_clf}\n",
        "model_scores = cross_eval_models(model_dict, X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m232/232\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.71      0.70      2490\n",
            "           1       0.61      0.52      0.56      1808\n",
            "           2       0.65      0.70      0.67      3111\n",
            "\n",
            "    accuracy                           0.66      7409\n",
            "   macro avg       0.65      0.64      0.64      7409\n",
            "weighted avg       0.65      0.66      0.65      7409\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = keras_model_scaled.predict(X_valid_scaled)\n",
        "\n",
        "keras_scores = classification_report(y_valid, y_pred.argmax(axis=1))\n",
        "print(keras_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optimisation des hyperparamètres\n",
        "\n",
        "7. **Modèle de référence :**\n",
        "\n",
        "    - Pour assurer une comparaison équitable avec notre modèle de référence, nous examinerons comment la variation des hyperparamètres affecte ses performances. Cela évite la conclusion erronée selon laquelle les réseaux de neurones sont intrinsèquement meilleurs, alors qu'en réalité, un ajustement adéquat des hyperparamètres pourrait améliorer les performances du modèle de référence.\n",
        "\n",
        "    - Concentrez-vous sur les hyperparamètres suivants pour chaque modèle :\n",
        "\n",
        "        - [DecisionTreeClassifier](https://scikit-learn.org/dev/modules/generated/sklearn.tree.DecisionTreeClassifier.html) : `criterion` et `max_depth`.\n",
        "  \n",
        "        - [LogisticRegression](https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html) : `penalty`, `max_iter`, et `tol`.\n",
        "  \n",
        "        - [KNeighborsClassifier](https://scikit-learn.org/dev/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) : `n_neighbors` et `weights`.\n",
        "\n",
        "    - Utilisez une stratégie de recherche par grille ou les méthodes intégrées de scikit-learn [GridSearchCV](https://scikit-learn.org/dev/modules/generated/sklearn.model_selection.GridSearchCV.html) pour évaluer de manière exhaustive toutes les combinaisons de valeurs d'hyperparamètres. La validation croisée doit être utilisée pour évaluer chaque combinaison.\n",
        "\n",
        "    - Quantifiez les performances de chaque configuration d'hyperparamètres en utilisant des métriques telles que la précision, le rappel et le score F1.\n",
        "\n",
        "    - Analysez les résultats et fournissez des aperçus sur quelles configurations d'hyperparamètres ont obtenu des performances optimales pour chaque modèle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Code cell\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "def grid_search(model, param_grid, X_train_, y_train_, X_test_, y_test_):\n",
        "    grid = GridSearchCV(model, param_grid, cv=5, n_jobs=-1)\n",
        "    grid.fit(X_train_, y_train_)\n",
        "    print(f\"Best hyperparameters: {grid.best_params_}\")\n",
        "    print(f\"Best score: {grid.best_score_}\")\n",
        "    \n",
        "    best_model = grid.best_estimator_\n",
        "    y_pred = best_model.predict(X_test_)\n",
        "    \n",
        "    report = classification_report(y_test_, y_pred)\n",
        "    print(f\"Classification report:\\n{report}\")\n",
        "        \n",
        "    return grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "param_grid_dt = [\n",
        "    {'max_depth': range(1, 10), # default = None\n",
        "   'criterion': [\"gini\", \"entropy\", \"log_loss\"] }, # default = gini\n",
        "]\n",
        "param_grid_kn = [\n",
        "  {'n_neighbors': range(3, 10),  # default = 5\n",
        "   'weights': [\"uniform\", \"distance\"]} # default = uniform\n",
        "]\n",
        "param_grid_lr = [ \n",
        "  {'penalty': [\"l2\", None], # default = l2 (Note: default solver lbfgs supports only 'l2' or None penalties, so \"elasticnet\" and \"l1\" are not supported)\n",
        "   'max_iter' : [100, 200, 400, 800, 1600], # default = 100\n",
        "   'tol' : [0.01, 0.001, 0.0001]} # default = 1e-4 \n",
        "] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best hyperparameters: {'criterion': 'log_loss', 'max_depth': 9}\n",
            "Best score: 0.5596404377843415\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.67      0.56      2490\n",
            "           1       0.52      0.30      0.38      1808\n",
            "           2       0.62      0.58      0.60      3111\n",
            "\n",
            "    accuracy                           0.54      7409\n",
            "   macro avg       0.54      0.52      0.51      7409\n",
            "weighted avg       0.55      0.54      0.53      7409\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dt_model = DecisionTreeClassifier()\n",
        "dt_grid = grid_search(dt_model, param_grid_dt, X_train_scaled, y_train, X_valid_scaled, y_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best hyperparameters: {'n_neighbors': 7, 'weights': 'distance'}\n",
            "Best score: 0.48765664712746826\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.81      0.54      2490\n",
            "           1       0.50      0.17      0.26      1808\n",
            "           2       0.56      0.32      0.41      3111\n",
            "\n",
            "    accuracy                           0.45      7409\n",
            "   macro avg       0.49      0.44      0.40      7409\n",
            "weighted avg       0.49      0.45      0.42      7409\n",
            "\n"
          ]
        }
      ],
      "source": [
        "knn_model = KNeighborsClassifier()\n",
        "knn_grid = grid_search(knn_model, param_grid_kn, X_train_scaled, y_train, X_valid_scaled, y_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best hyperparameters: {'max_iter': 100, 'penalty': None, 'tol': 0.001}\n",
            "Best score: 0.6867269059436764\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.71      0.69      2490\n",
            "           1       0.66      0.46      0.54      1808\n",
            "           2       0.68      0.76      0.72      3111\n",
            "\n",
            "    accuracy                           0.67      7409\n",
            "   macro avg       0.67      0.65      0.65      7409\n",
            "weighted avg       0.67      0.67      0.67      7409\n",
            "\n"
          ]
        }
      ],
      "source": [
        "lr_model = LogisticRegression()\n",
        "lr_grid = grid_search(lr_model, param_grid_lr, X_train_scaled, y_train, X_valid_scaled, y_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> ## Observations\n",
        "> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "8. **Réseau de neurones :**\n",
        "\n",
        "    Lors de notre exploration et ajustement des réseaux de neurones, nous nous concentrons sur les hyperparamètres suivants :\n",
        "\n",
        "    - **Une seule couche cachée, en variant le nombre de nœuds**. \n",
        "\n",
        "        - Commencez avec un seul nœud dans la couche cachée. Utilisez un graphique pour représenter l'évolution de la perte et de la précision pour les ensembles d'entraînement et de validation, avec l'axe horizontal représentant le nombre d'époques d'entraînement et l'axe vertical représentant la perte et la précision. L'entraînement de ce réseau devrait être relativement rapide, nous allons donc procéder à un entraînement sur 50 époques. Que concluez-vous de l'observation du graphique ? Le réseau sous-apprend-il ou surapprend-il ? Pourquoi ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Code cell\n",
        "def create_model_with_hidden_layer(num_node, epochs=50):\n",
        "    print(f\"Creating model with {num_node}\")\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Dense(462, input_dim=462, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(num_node))\n",
        "    model.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
        "    \n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
        "    history = model.fit(X_train_scaled, y_train, validation_data=(X_valid_scaled, y_valid), epochs=epochs)\n",
        "    return history\n",
        "\n",
        "histories = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kc/dev/2249/CSI4506/Devoir3/venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4107 - loss: 1.0553 - val_accuracy: 0.4735 - val_loss: 0.9993\n",
            "Epoch 2/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.4731 - loss: 0.9646 - val_accuracy: 0.4995 - val_loss: 0.9622\n",
            "Epoch 3/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.4828 - loss: 0.9361 - val_accuracy: 0.4986 - val_loss: 0.9562\n",
            "Epoch 4/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.4840 - loss: 0.9292 - val_accuracy: 0.4913 - val_loss: 0.9523\n",
            "Epoch 5/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4925 - loss: 0.9229 - val_accuracy: 0.5052 - val_loss: 0.9461\n",
            "Epoch 6/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5201 - loss: 0.9126 - val_accuracy: 0.5236 - val_loss: 0.9344\n",
            "Epoch 7/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503us/step - accuracy: 0.5529 - loss: 0.8956 - val_accuracy: 0.5439 - val_loss: 0.9186\n",
            "Epoch 8/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5762 - loss: 0.8762 - val_accuracy: 0.5576 - val_loss: 0.9043\n",
            "Epoch 9/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5933 - loss: 0.8590 - val_accuracy: 0.5684 - val_loss: 0.8932\n",
            "Epoch 10/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6047 - loss: 0.8437 - val_accuracy: 0.5761 - val_loss: 0.8833\n",
            "Epoch 11/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6159 - loss: 0.8280 - val_accuracy: 0.5862 - val_loss: 0.8732\n",
            "Epoch 12/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6281 - loss: 0.8099 - val_accuracy: 0.5959 - val_loss: 0.8621\n",
            "Epoch 13/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6428 - loss: 0.7879 - val_accuracy: 0.6022 - val_loss: 0.8500\n",
            "Epoch 14/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6608 - loss: 0.7617 - val_accuracy: 0.6101 - val_loss: 0.8380\n",
            "Epoch 15/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6779 - loss: 0.7328 - val_accuracy: 0.6199 - val_loss: 0.8282\n",
            "Epoch 16/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6952 - loss: 0.7035 - val_accuracy: 0.6282 - val_loss: 0.8219\n",
            "Epoch 17/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7092 - loss: 0.6753 - val_accuracy: 0.6300 - val_loss: 0.8198\n",
            "Epoch 18/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7206 - loss: 0.6482 - val_accuracy: 0.6315 - val_loss: 0.8213\n",
            "Epoch 19/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 473us/step - accuracy: 0.7342 - loss: 0.6218 - val_accuracy: 0.6303 - val_loss: 0.8270\n",
            "Epoch 20/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7488 - loss: 0.5954 - val_accuracy: 0.6313 - val_loss: 0.8357\n",
            "Epoch 21/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7626 - loss: 0.5689 - val_accuracy: 0.6333 - val_loss: 0.8477\n",
            "Epoch 22/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7751 - loss: 0.5424 - val_accuracy: 0.6329 - val_loss: 0.8628\n",
            "Epoch 23/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7905 - loss: 0.5157 - val_accuracy: 0.6327 - val_loss: 0.8812\n",
            "Epoch 24/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8056 - loss: 0.4891 - val_accuracy: 0.6307 - val_loss: 0.9044\n",
            "Epoch 25/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8191 - loss: 0.4623 - val_accuracy: 0.6302 - val_loss: 0.9299\n",
            "Epoch 26/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8318 - loss: 0.4357 - val_accuracy: 0.6303 - val_loss: 0.9586\n",
            "Epoch 27/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8472 - loss: 0.4090 - val_accuracy: 0.6252 - val_loss: 0.9910\n",
            "Epoch 28/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8607 - loss: 0.3826 - val_accuracy: 0.6207 - val_loss: 1.0288\n",
            "Epoch 29/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8734 - loss: 0.3565 - val_accuracy: 0.6168 - val_loss: 1.0674\n",
            "Epoch 30/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8869 - loss: 0.3307 - val_accuracy: 0.6147 - val_loss: 1.1108\n"
          ]
        }
      ],
      "source": [
        "histories[1] = create_model_with_hidden_layer(1,50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Répétez le processus ci-dessus en utilisant 2 et 4 nœuds dans la couche cachée. Utilisez le même type de graphique pour documenter vos observations concernant la perte et la précision."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kc/dev/2249/CSI4506/Devoir3/venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.4467 - loss: 1.0445 - val_accuracy: 0.5589 - val_loss: 0.9473\n",
            "Epoch 2/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 453us/step - accuracy: 0.6040 - loss: 0.8785 - val_accuracy: 0.6453 - val_loss: 0.8058\n",
            "Epoch 3/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6754 - loss: 0.7637 - val_accuracy: 0.6681 - val_loss: 0.7742\n",
            "Epoch 4/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6884 - loss: 0.7360 - val_accuracy: 0.6739 - val_loss: 0.7687\n",
            "Epoch 5/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6937 - loss: 0.7267 - val_accuracy: 0.6744 - val_loss: 0.7664\n",
            "Epoch 6/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6964 - loss: 0.7202 - val_accuracy: 0.6746 - val_loss: 0.7647\n",
            "Epoch 7/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6995 - loss: 0.7139 - val_accuracy: 0.6761 - val_loss: 0.7628\n",
            "Epoch 8/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7025 - loss: 0.7069 - val_accuracy: 0.6782 - val_loss: 0.7605\n",
            "Epoch 9/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7066 - loss: 0.6988 - val_accuracy: 0.6793 - val_loss: 0.7575\n",
            "Epoch 10/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7110 - loss: 0.6890 - val_accuracy: 0.6798 - val_loss: 0.7535\n",
            "Epoch 11/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7172 - loss: 0.6771 - val_accuracy: 0.6830 - val_loss: 0.7486\n",
            "Epoch 12/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7233 - loss: 0.6625 - val_accuracy: 0.6823 - val_loss: 0.7428\n",
            "Epoch 13/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7330 - loss: 0.6448 - val_accuracy: 0.6855 - val_loss: 0.7365\n",
            "Epoch 14/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 449us/step - accuracy: 0.7439 - loss: 0.6245 - val_accuracy: 0.6902 - val_loss: 0.7306\n",
            "Epoch 15/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7554 - loss: 0.6022 - val_accuracy: 0.6911 - val_loss: 0.7266\n",
            "Epoch 16/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7652 - loss: 0.5790 - val_accuracy: 0.6933 - val_loss: 0.7253\n",
            "Epoch 17/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7752 - loss: 0.5552 - val_accuracy: 0.6935 - val_loss: 0.7267\n",
            "Epoch 18/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7871 - loss: 0.5308 - val_accuracy: 0.6948 - val_loss: 0.7310\n",
            "Epoch 19/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7982 - loss: 0.5056 - val_accuracy: 0.6921 - val_loss: 0.7386\n",
            "Epoch 20/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8112 - loss: 0.4796 - val_accuracy: 0.6913 - val_loss: 0.7490\n",
            "Epoch 21/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8253 - loss: 0.4530 - val_accuracy: 0.6892 - val_loss: 0.7624\n",
            "Epoch 22/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8380 - loss: 0.4259 - val_accuracy: 0.6870 - val_loss: 0.7792\n",
            "Epoch 23/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8524 - loss: 0.3983 - val_accuracy: 0.6827 - val_loss: 0.7988\n",
            "Epoch 24/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8650 - loss: 0.3708 - val_accuracy: 0.6838 - val_loss: 0.8199\n",
            "Epoch 25/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8771 - loss: 0.3434 - val_accuracy: 0.6825 - val_loss: 0.8436\n",
            "Epoch 26/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 447us/step - accuracy: 0.8911 - loss: 0.3163 - val_accuracy: 0.6792 - val_loss: 0.8695\n",
            "Epoch 27/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9039 - loss: 0.2899 - val_accuracy: 0.6771 - val_loss: 0.8975\n",
            "Epoch 28/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9153 - loss: 0.2642 - val_accuracy: 0.6747 - val_loss: 0.9282\n",
            "Epoch 29/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9259 - loss: 0.2394 - val_accuracy: 0.6730 - val_loss: 0.9627\n",
            "Epoch 30/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9368 - loss: 0.2154 - val_accuracy: 0.6713 - val_loss: 0.9986\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kc/dev/2249/CSI4506/Devoir3/venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.4651 - loss: 1.0509 - val_accuracy: 0.5674 - val_loss: 0.9496\n",
            "Epoch 2/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6197 - loss: 0.8710 - val_accuracy: 0.6556 - val_loss: 0.7959\n",
            "Epoch 3/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6788 - loss: 0.7565 - val_accuracy: 0.6655 - val_loss: 0.7760\n",
            "Epoch 4/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6891 - loss: 0.7377 - val_accuracy: 0.6688 - val_loss: 0.7723\n",
            "Epoch 5/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6926 - loss: 0.7299 - val_accuracy: 0.6695 - val_loss: 0.7707\n",
            "Epoch 6/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6948 - loss: 0.7242 - val_accuracy: 0.6709 - val_loss: 0.7696\n",
            "Epoch 7/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 428us/step - accuracy: 0.6978 - loss: 0.7188 - val_accuracy: 0.6712 - val_loss: 0.7685\n",
            "Epoch 8/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7004 - loss: 0.7133 - val_accuracy: 0.6720 - val_loss: 0.7674\n",
            "Epoch 9/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7037 - loss: 0.7072 - val_accuracy: 0.6744 - val_loss: 0.7660\n",
            "Epoch 10/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7069 - loss: 0.7002 - val_accuracy: 0.6749 - val_loss: 0.7643\n",
            "Epoch 11/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7104 - loss: 0.6919 - val_accuracy: 0.6751 - val_loss: 0.7622\n",
            "Epoch 12/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7154 - loss: 0.6821 - val_accuracy: 0.6767 - val_loss: 0.7596\n",
            "Epoch 13/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7228 - loss: 0.6700 - val_accuracy: 0.6792 - val_loss: 0.7560\n",
            "Epoch 14/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7315 - loss: 0.6551 - val_accuracy: 0.6792 - val_loss: 0.7513\n",
            "Epoch 15/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7407 - loss: 0.6368 - val_accuracy: 0.6800 - val_loss: 0.7462\n",
            "Epoch 16/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7515 - loss: 0.6152 - val_accuracy: 0.6824 - val_loss: 0.7411\n",
            "Epoch 17/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7640 - loss: 0.5911 - val_accuracy: 0.6866 - val_loss: 0.7377\n",
            "Epoch 18/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7756 - loss: 0.5656 - val_accuracy: 0.6877 - val_loss: 0.7374\n",
            "Epoch 19/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 413us/step - accuracy: 0.7871 - loss: 0.5395 - val_accuracy: 0.6884 - val_loss: 0.7403\n",
            "Epoch 20/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7999 - loss: 0.5128 - val_accuracy: 0.6855 - val_loss: 0.7467\n",
            "Epoch 21/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8120 - loss: 0.4854 - val_accuracy: 0.6850 - val_loss: 0.7562\n",
            "Epoch 22/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8255 - loss: 0.4574 - val_accuracy: 0.6840 - val_loss: 0.7691\n",
            "Epoch 23/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8384 - loss: 0.4290 - val_accuracy: 0.6854 - val_loss: 0.7853\n",
            "Epoch 24/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8505 - loss: 0.4002 - val_accuracy: 0.6834 - val_loss: 0.8046\n",
            "Epoch 25/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8641 - loss: 0.3715 - val_accuracy: 0.6798 - val_loss: 0.8272\n",
            "Epoch 26/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8779 - loss: 0.3428 - val_accuracy: 0.6777 - val_loss: 0.8534\n",
            "Epoch 27/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8914 - loss: 0.3146 - val_accuracy: 0.6753 - val_loss: 0.8822\n",
            "Epoch 28/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9048 - loss: 0.2869 - val_accuracy: 0.6743 - val_loss: 0.9140\n",
            "Epoch 29/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9178 - loss: 0.2600 - val_accuracy: 0.6724 - val_loss: 0.9488\n",
            "Epoch 30/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9296 - loss: 0.2338 - val_accuracy: 0.6696 - val_loss: 0.9857\n",
            "Epoch 31/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 425us/step - accuracy: 0.9404 - loss: 0.2086 - val_accuracy: 0.6692 - val_loss: 1.0246\n",
            "Epoch 32/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9501 - loss: 0.1847 - val_accuracy: 0.6670 - val_loss: 1.0652\n",
            "Epoch 33/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9593 - loss: 0.1624 - val_accuracy: 0.6655 - val_loss: 1.1072\n",
            "Epoch 34/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9680 - loss: 0.1419 - val_accuracy: 0.6645 - val_loss: 1.1509\n",
            "Epoch 35/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9744 - loss: 0.1234 - val_accuracy: 0.6646 - val_loss: 1.1956\n",
            "Epoch 36/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9801 - loss: 0.1068 - val_accuracy: 0.6639 - val_loss: 1.2396\n",
            "Epoch 37/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9843 - loss: 0.0921 - val_accuracy: 0.6620 - val_loss: 1.2831\n",
            "Epoch 38/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9881 - loss: 0.0794 - val_accuracy: 0.6604 - val_loss: 1.3237\n",
            "Epoch 39/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9914 - loss: 0.0684 - val_accuracy: 0.6603 - val_loss: 1.3637\n",
            "Epoch 40/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9938 - loss: 0.0590 - val_accuracy: 0.6580 - val_loss: 1.4016\n",
            "Epoch 41/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9954 - loss: 0.0511 - val_accuracy: 0.6577 - val_loss: 1.4396\n",
            "Epoch 42/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 430us/step - accuracy: 0.9965 - loss: 0.0443 - val_accuracy: 0.6580 - val_loss: 1.4745\n",
            "Epoch 43/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9975 - loss: 0.0387 - val_accuracy: 0.6574 - val_loss: 1.5078\n",
            "Epoch 44/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9984 - loss: 0.0339 - val_accuracy: 0.6584 - val_loss: 1.5384\n",
            "Epoch 45/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9988 - loss: 0.0299 - val_accuracy: 0.6584 - val_loss: 1.5662\n",
            "Epoch 46/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9990 - loss: 0.0265 - val_accuracy: 0.6589 - val_loss: 1.5932\n",
            "Epoch 47/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9994 - loss: 0.0236 - val_accuracy: 0.6603 - val_loss: 1.6179\n",
            "Epoch 48/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9998 - loss: 0.0211 - val_accuracy: 0.6601 - val_loss: 1.6413\n",
            "Epoch 49/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9998 - loss: 0.0191 - val_accuracy: 0.6591 - val_loss: 1.6624\n",
            "Epoch 50/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9999 - loss: 0.0173 - val_accuracy: 0.6577 - val_loss: 1.6828\n"
          ]
        }
      ],
      "source": [
        "# Code cell\n",
        "histories[2] = create_model_with_hidden_layer(2,30)\n",
        "histories[4] = create_model_with_hidden_layer(4,50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Commencez avec 8 nœuds dans la couche cachée et doublez progressivement le nombre de nœuds jusqu'à ce qu'il dépasse le nombre de nœuds dans la couche d'entrée. Cela donne lieu à sept expériences et graphiques correspondants pour les configurations suivantes : 8, 16, 32, 64, 128, 256 et 512 nœuds. Documentez vos observations tout au long du processus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kc/dev/2249/CSI4506/Devoir3/venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4777 - loss: 1.0206 - val_accuracy: 0.6299 - val_loss: 0.8684\n",
            "Epoch 2/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6613 - loss: 0.8008 - val_accuracy: 0.6608 - val_loss: 0.7808\n",
            "Epoch 3/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6864 - loss: 0.7429 - val_accuracy: 0.6678 - val_loss: 0.7716\n",
            "Epoch 4/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6917 - loss: 0.7307 - val_accuracy: 0.6695 - val_loss: 0.7690\n",
            "Epoch 5/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 491us/step - accuracy: 0.6942 - loss: 0.7235 - val_accuracy: 0.6709 - val_loss: 0.7674\n",
            "Epoch 6/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6976 - loss: 0.7171 - val_accuracy: 0.6727 - val_loss: 0.7658\n",
            "Epoch 7/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7002 - loss: 0.7104 - val_accuracy: 0.6730 - val_loss: 0.7640\n",
            "Epoch 8/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7043 - loss: 0.7028 - val_accuracy: 0.6753 - val_loss: 0.7620\n",
            "Epoch 9/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7090 - loss: 0.6941 - val_accuracy: 0.6749 - val_loss: 0.7593\n",
            "Epoch 10/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7144 - loss: 0.6838 - val_accuracy: 0.6743 - val_loss: 0.7561\n",
            "Epoch 11/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7211 - loss: 0.6712 - val_accuracy: 0.6785 - val_loss: 0.7520\n",
            "Epoch 12/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7283 - loss: 0.6557 - val_accuracy: 0.6807 - val_loss: 0.7469\n",
            "Epoch 13/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7374 - loss: 0.6368 - val_accuracy: 0.6854 - val_loss: 0.7409\n",
            "Epoch 14/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7479 - loss: 0.6144 - val_accuracy: 0.6913 - val_loss: 0.7348\n",
            "Epoch 15/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 892us/step - accuracy: 0.7602 - loss: 0.5893 - val_accuracy: 0.6906 - val_loss: 0.7304\n",
            "Epoch 16/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7740 - loss: 0.5629 - val_accuracy: 0.6936 - val_loss: 0.7297\n",
            "Epoch 17/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7869 - loss: 0.5364 - val_accuracy: 0.6938 - val_loss: 0.7323\n",
            "Epoch 18/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7989 - loss: 0.5097 - val_accuracy: 0.6942 - val_loss: 0.7389\n",
            "Epoch 19/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8106 - loss: 0.4825 - val_accuracy: 0.6909 - val_loss: 0.7492\n",
            "Epoch 20/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8230 - loss: 0.4549 - val_accuracy: 0.6896 - val_loss: 0.7628\n",
            "Epoch 21/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8377 - loss: 0.4270 - val_accuracy: 0.6847 - val_loss: 0.7798\n",
            "Epoch 22/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8528 - loss: 0.3990 - val_accuracy: 0.6820 - val_loss: 0.8001\n",
            "Epoch 23/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8651 - loss: 0.3706 - val_accuracy: 0.6782 - val_loss: 0.8224\n",
            "Epoch 24/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8783 - loss: 0.3424 - val_accuracy: 0.6757 - val_loss: 0.8464\n",
            "Epoch 25/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8915 - loss: 0.3146 - val_accuracy: 0.6736 - val_loss: 0.8728\n",
            "Epoch 26/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 472us/step - accuracy: 0.9037 - loss: 0.2874 - val_accuracy: 0.6695 - val_loss: 0.9028\n",
            "Epoch 27/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9163 - loss: 0.2608 - val_accuracy: 0.6691 - val_loss: 0.9351\n",
            "Epoch 28/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9275 - loss: 0.2350 - val_accuracy: 0.6684 - val_loss: 0.9702\n",
            "Epoch 29/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9396 - loss: 0.2102 - val_accuracy: 0.6654 - val_loss: 1.0047\n",
            "Epoch 30/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9495 - loss: 0.1867 - val_accuracy: 0.6639 - val_loss: 1.0414\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kc/dev/2249/CSI4506/Devoir3/venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4946 - loss: 1.0169 - val_accuracy: 0.6276 - val_loss: 0.8553\n",
            "Epoch 2/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6658 - loss: 0.7916 - val_accuracy: 0.6653 - val_loss: 0.7837\n",
            "Epoch 3/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6859 - loss: 0.7423 - val_accuracy: 0.6699 - val_loss: 0.7755\n",
            "Epoch 4/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6913 - loss: 0.7313 - val_accuracy: 0.6718 - val_loss: 0.7726\n",
            "Epoch 5/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6935 - loss: 0.7245 - val_accuracy: 0.6726 - val_loss: 0.7708\n",
            "Epoch 6/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6968 - loss: 0.7182 - val_accuracy: 0.6727 - val_loss: 0.7691\n",
            "Epoch 7/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 473us/step - accuracy: 0.7000 - loss: 0.7118 - val_accuracy: 0.6747 - val_loss: 0.7674\n",
            "Epoch 8/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7033 - loss: 0.7046 - val_accuracy: 0.6749 - val_loss: 0.7653\n",
            "Epoch 9/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7074 - loss: 0.6963 - val_accuracy: 0.6755 - val_loss: 0.7628\n",
            "Epoch 10/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7126 - loss: 0.6864 - val_accuracy: 0.6766 - val_loss: 0.7594\n",
            "Epoch 11/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7185 - loss: 0.6743 - val_accuracy: 0.6780 - val_loss: 0.7549\n",
            "Epoch 12/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7258 - loss: 0.6594 - val_accuracy: 0.6804 - val_loss: 0.7494\n",
            "Epoch 13/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7348 - loss: 0.6411 - val_accuracy: 0.6827 - val_loss: 0.7434\n",
            "Epoch 14/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7462 - loss: 0.6195 - val_accuracy: 0.6879 - val_loss: 0.7378\n",
            "Epoch 15/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7570 - loss: 0.5954 - val_accuracy: 0.6916 - val_loss: 0.7342\n",
            "Epoch 16/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7688 - loss: 0.5700 - val_accuracy: 0.6927 - val_loss: 0.7336\n",
            "Epoch 17/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7818 - loss: 0.5440 - val_accuracy: 0.6920 - val_loss: 0.7365\n",
            "Epoch 18/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7945 - loss: 0.5175 - val_accuracy: 0.6886 - val_loss: 0.7427\n",
            "Epoch 19/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 469us/step - accuracy: 0.8073 - loss: 0.4907 - val_accuracy: 0.6870 - val_loss: 0.7519\n",
            "Epoch 20/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8211 - loss: 0.4630 - val_accuracy: 0.6859 - val_loss: 0.7639\n",
            "Epoch 21/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8348 - loss: 0.4347 - val_accuracy: 0.6832 - val_loss: 0.7790\n",
            "Epoch 22/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8484 - loss: 0.4060 - val_accuracy: 0.6816 - val_loss: 0.7966\n",
            "Epoch 23/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8610 - loss: 0.3772 - val_accuracy: 0.6796 - val_loss: 0.8174\n",
            "Epoch 24/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8751 - loss: 0.3485 - val_accuracy: 0.6786 - val_loss: 0.8411\n",
            "Epoch 25/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8880 - loss: 0.3202 - val_accuracy: 0.6753 - val_loss: 0.8683\n",
            "Epoch 26/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9014 - loss: 0.2925 - val_accuracy: 0.6739 - val_loss: 0.8996\n",
            "Epoch 27/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9141 - loss: 0.2652 - val_accuracy: 0.6708 - val_loss: 0.9330\n",
            "Epoch 28/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9269 - loss: 0.2389 - val_accuracy: 0.6684 - val_loss: 0.9689\n",
            "Epoch 29/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9388 - loss: 0.2135 - val_accuracy: 0.6662 - val_loss: 1.0064\n",
            "Epoch 30/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 483us/step - accuracy: 0.9487 - loss: 0.1893 - val_accuracy: 0.6634 - val_loss: 1.0457\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kc/dev/2249/CSI4506/Devoir3/venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5069 - loss: 1.0071 - val_accuracy: 0.6276 - val_loss: 0.8436\n",
            "Epoch 2/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6639 - loss: 0.7899 - val_accuracy: 0.6641 - val_loss: 0.7788\n",
            "Epoch 3/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6861 - loss: 0.7430 - val_accuracy: 0.6711 - val_loss: 0.7711\n",
            "Epoch 4/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6915 - loss: 0.7311 - val_accuracy: 0.6715 - val_loss: 0.7684\n",
            "Epoch 5/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6959 - loss: 0.7237 - val_accuracy: 0.6732 - val_loss: 0.7666\n",
            "Epoch 6/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6992 - loss: 0.7170 - val_accuracy: 0.6747 - val_loss: 0.7645\n",
            "Epoch 7/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7029 - loss: 0.7101 - val_accuracy: 0.6758 - val_loss: 0.7625\n",
            "Epoch 8/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7071 - loss: 0.7024 - val_accuracy: 0.6776 - val_loss: 0.7601\n",
            "Epoch 9/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7114 - loss: 0.6936 - val_accuracy: 0.6785 - val_loss: 0.7570\n",
            "Epoch 10/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 865us/step - accuracy: 0.7159 - loss: 0.6830 - val_accuracy: 0.6807 - val_loss: 0.7532\n",
            "Epoch 11/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7221 - loss: 0.6702 - val_accuracy: 0.6823 - val_loss: 0.7481\n",
            "Epoch 12/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7301 - loss: 0.6545 - val_accuracy: 0.6851 - val_loss: 0.7423\n",
            "Epoch 13/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7404 - loss: 0.6359 - val_accuracy: 0.6879 - val_loss: 0.7362\n",
            "Epoch 14/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7499 - loss: 0.6144 - val_accuracy: 0.6908 - val_loss: 0.7308\n",
            "Epoch 15/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7613 - loss: 0.5908 - val_accuracy: 0.6919 - val_loss: 0.7277\n",
            "Epoch 16/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7721 - loss: 0.5662 - val_accuracy: 0.6950 - val_loss: 0.7276\n",
            "Epoch 17/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7844 - loss: 0.5411 - val_accuracy: 0.6928 - val_loss: 0.7312\n",
            "Epoch 18/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7959 - loss: 0.5156 - val_accuracy: 0.6933 - val_loss: 0.7375\n",
            "Epoch 19/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 488us/step - accuracy: 0.8076 - loss: 0.4896 - val_accuracy: 0.6920 - val_loss: 0.7471\n",
            "Epoch 20/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8199 - loss: 0.4631 - val_accuracy: 0.6889 - val_loss: 0.7597\n",
            "Epoch 21/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8330 - loss: 0.4362 - val_accuracy: 0.6865 - val_loss: 0.7761\n",
            "Epoch 22/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8461 - loss: 0.4090 - val_accuracy: 0.6836 - val_loss: 0.7962\n",
            "Epoch 23/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8591 - loss: 0.3815 - val_accuracy: 0.6794 - val_loss: 0.8202\n",
            "Epoch 24/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8729 - loss: 0.3540 - val_accuracy: 0.6777 - val_loss: 0.8474\n",
            "Epoch 25/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8868 - loss: 0.3267 - val_accuracy: 0.6743 - val_loss: 0.8766\n",
            "Epoch 26/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8986 - loss: 0.2997 - val_accuracy: 0.6728 - val_loss: 0.9088\n",
            "Epoch 27/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9098 - loss: 0.2734 - val_accuracy: 0.6699 - val_loss: 0.9436\n",
            "Epoch 28/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9220 - loss: 0.2477 - val_accuracy: 0.6684 - val_loss: 0.9804\n",
            "Epoch 29/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9340 - loss: 0.2229 - val_accuracy: 0.6664 - val_loss: 1.0182\n",
            "Epoch 30/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 555us/step - accuracy: 0.9439 - loss: 0.1992 - val_accuracy: 0.6634 - val_loss: 1.0577\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kc/dev/2249/CSI4506/Devoir3/venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5159 - loss: 1.0007 - val_accuracy: 0.6311 - val_loss: 0.8335\n",
            "Epoch 2/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6684 - loss: 0.7809 - val_accuracy: 0.6614 - val_loss: 0.7783\n",
            "Epoch 3/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6858 - loss: 0.7406 - val_accuracy: 0.6691 - val_loss: 0.7715\n",
            "Epoch 4/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6923 - loss: 0.7301 - val_accuracy: 0.6697 - val_loss: 0.7687\n",
            "Epoch 5/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6960 - loss: 0.7230 - val_accuracy: 0.6709 - val_loss: 0.7666\n",
            "Epoch 6/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6991 - loss: 0.7163 - val_accuracy: 0.6734 - val_loss: 0.7646\n",
            "Epoch 7/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7019 - loss: 0.7092 - val_accuracy: 0.6758 - val_loss: 0.7622\n",
            "Epoch 8/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7060 - loss: 0.7010 - val_accuracy: 0.6770 - val_loss: 0.7593\n",
            "Epoch 9/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7108 - loss: 0.6914 - val_accuracy: 0.6788 - val_loss: 0.7557\n",
            "Epoch 10/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7162 - loss: 0.6799 - val_accuracy: 0.6811 - val_loss: 0.7514\n",
            "Epoch 11/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 349us/step - accuracy: 0.7233 - loss: 0.6659 - val_accuracy: 0.6830 - val_loss: 0.7462\n",
            "Epoch 12/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7333 - loss: 0.6490 - val_accuracy: 0.6846 - val_loss: 0.7406\n",
            "Epoch 13/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7421 - loss: 0.6292 - val_accuracy: 0.6905 - val_loss: 0.7352\n",
            "Epoch 14/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7528 - loss: 0.6071 - val_accuracy: 0.6912 - val_loss: 0.7310\n",
            "Epoch 15/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7637 - loss: 0.5836 - val_accuracy: 0.6920 - val_loss: 0.7291\n",
            "Epoch 16/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7749 - loss: 0.5592 - val_accuracy: 0.6923 - val_loss: 0.7295\n",
            "Epoch 17/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7866 - loss: 0.5342 - val_accuracy: 0.6954 - val_loss: 0.7329\n",
            "Epoch 18/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7986 - loss: 0.5084 - val_accuracy: 0.6955 - val_loss: 0.7393\n",
            "Epoch 19/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8110 - loss: 0.4817 - val_accuracy: 0.6943 - val_loss: 0.7487\n",
            "Epoch 20/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8245 - loss: 0.4543 - val_accuracy: 0.6944 - val_loss: 0.7611\n",
            "Epoch 21/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8382 - loss: 0.4261 - val_accuracy: 0.6913 - val_loss: 0.7773\n",
            "Epoch 22/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8520 - loss: 0.3977 - val_accuracy: 0.6886 - val_loss: 0.7964\n",
            "Epoch 23/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8664 - loss: 0.3690 - val_accuracy: 0.6854 - val_loss: 0.8192\n",
            "Epoch 24/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8798 - loss: 0.3405 - val_accuracy: 0.6821 - val_loss: 0.8439\n",
            "Epoch 25/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8940 - loss: 0.3122 - val_accuracy: 0.6798 - val_loss: 0.8723\n",
            "Epoch 26/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9070 - loss: 0.2845 - val_accuracy: 0.6755 - val_loss: 0.9030\n",
            "Epoch 27/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9193 - loss: 0.2576 - val_accuracy: 0.6744 - val_loss: 0.9358\n",
            "Epoch 28/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9304 - loss: 0.2317 - val_accuracy: 0.6747 - val_loss: 0.9713\n",
            "Epoch 29/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9408 - loss: 0.2069 - val_accuracy: 0.6728 - val_loss: 1.0082\n",
            "Epoch 30/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.9502 - loss: 0.1834 - val_accuracy: 0.6704 - val_loss: 1.0475\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kc/dev/2249/CSI4506/Devoir3/venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5020 - loss: 1.0162 - val_accuracy: 0.6249 - val_loss: 0.8502\n",
            "Epoch 2/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724us/step - accuracy: 0.6641 - loss: 0.7932 - val_accuracy: 0.6684 - val_loss: 0.7777\n",
            "Epoch 3/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6860 - loss: 0.7438 - val_accuracy: 0.6744 - val_loss: 0.7697\n",
            "Epoch 4/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6906 - loss: 0.7327 - val_accuracy: 0.6766 - val_loss: 0.7671\n",
            "Epoch 5/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6939 - loss: 0.7256 - val_accuracy: 0.6767 - val_loss: 0.7652\n",
            "Epoch 6/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6970 - loss: 0.7192 - val_accuracy: 0.6776 - val_loss: 0.7634\n",
            "Epoch 7/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7002 - loss: 0.7125 - val_accuracy: 0.6798 - val_loss: 0.7614\n",
            "Epoch 8/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7034 - loss: 0.7049 - val_accuracy: 0.6801 - val_loss: 0.7589\n",
            "Epoch 9/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7075 - loss: 0.6962 - val_accuracy: 0.6815 - val_loss: 0.7561\n",
            "Epoch 10/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7132 - loss: 0.6857 - val_accuracy: 0.6832 - val_loss: 0.7521\n",
            "Epoch 11/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 730us/step - accuracy: 0.7204 - loss: 0.6728 - val_accuracy: 0.6850 - val_loss: 0.7474\n",
            "Epoch 12/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7279 - loss: 0.6572 - val_accuracy: 0.6850 - val_loss: 0.7416\n",
            "Epoch 13/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7367 - loss: 0.6384 - val_accuracy: 0.6861 - val_loss: 0.7356\n",
            "Epoch 14/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7483 - loss: 0.6169 - val_accuracy: 0.6875 - val_loss: 0.7303\n",
            "Epoch 15/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7594 - loss: 0.5933 - val_accuracy: 0.6902 - val_loss: 0.7268\n",
            "Epoch 16/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7697 - loss: 0.5688 - val_accuracy: 0.6933 - val_loss: 0.7263\n",
            "Epoch 17/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7818 - loss: 0.5437 - val_accuracy: 0.6933 - val_loss: 0.7289\n",
            "Epoch 18/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7945 - loss: 0.5182 - val_accuracy: 0.6931 - val_loss: 0.7345\n",
            "Epoch 19/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8059 - loss: 0.4916 - val_accuracy: 0.6913 - val_loss: 0.7435\n",
            "Epoch 20/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step - accuracy: 0.8195 - loss: 0.4645 - val_accuracy: 0.6900 - val_loss: 0.7557\n",
            "Epoch 21/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8334 - loss: 0.4369 - val_accuracy: 0.6874 - val_loss: 0.7717\n",
            "Epoch 22/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8462 - loss: 0.4089 - val_accuracy: 0.6888 - val_loss: 0.7907\n",
            "Epoch 23/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8600 - loss: 0.3805 - val_accuracy: 0.6838 - val_loss: 0.8129\n",
            "Epoch 24/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8734 - loss: 0.3521 - val_accuracy: 0.6788 - val_loss: 0.8389\n",
            "Epoch 25/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8865 - loss: 0.3239 - val_accuracy: 0.6750 - val_loss: 0.8675\n",
            "Epoch 26/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9002 - loss: 0.2959 - val_accuracy: 0.6722 - val_loss: 0.9001\n",
            "Epoch 27/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2687 - val_accuracy: 0.6709 - val_loss: 0.9345\n",
            "Epoch 28/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9254 - loss: 0.2422 - val_accuracy: 0.6685 - val_loss: 0.9708\n",
            "Epoch 29/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9372 - loss: 0.2168 - val_accuracy: 0.6682 - val_loss: 1.0084\n",
            "Epoch 30/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9474 - loss: 0.1928 - val_accuracy: 0.6674 - val_loss: 1.0486\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kc/dev/2249/CSI4506/Devoir3/venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5046 - loss: 1.0115 - val_accuracy: 0.6290 - val_loss: 0.8434\n",
            "Epoch 2/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6664 - loss: 0.7873 - val_accuracy: 0.6676 - val_loss: 0.7799\n",
            "Epoch 3/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6862 - loss: 0.7427 - val_accuracy: 0.6738 - val_loss: 0.7716\n",
            "Epoch 4/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6916 - loss: 0.7316 - val_accuracy: 0.6736 - val_loss: 0.7685\n",
            "Epoch 5/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6939 - loss: 0.7246 - val_accuracy: 0.6753 - val_loss: 0.7663\n",
            "Epoch 6/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6967 - loss: 0.7181 - val_accuracy: 0.6758 - val_loss: 0.7643\n",
            "Epoch 7/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7002 - loss: 0.7114 - val_accuracy: 0.6785 - val_loss: 0.7621\n",
            "Epoch 8/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7038 - loss: 0.7040 - val_accuracy: 0.6813 - val_loss: 0.7593\n",
            "Epoch 9/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 762us/step - accuracy: 0.7078 - loss: 0.6951 - val_accuracy: 0.6840 - val_loss: 0.7557\n",
            "Epoch 10/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7128 - loss: 0.6845 - val_accuracy: 0.6859 - val_loss: 0.7513\n",
            "Epoch 11/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7193 - loss: 0.6715 - val_accuracy: 0.6885 - val_loss: 0.7460\n",
            "Epoch 12/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7275 - loss: 0.6555 - val_accuracy: 0.6898 - val_loss: 0.7396\n",
            "Epoch 13/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7366 - loss: 0.6364 - val_accuracy: 0.6921 - val_loss: 0.7334\n",
            "Epoch 14/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7482 - loss: 0.6144 - val_accuracy: 0.6927 - val_loss: 0.7280\n",
            "Epoch 15/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7593 - loss: 0.5907 - val_accuracy: 0.6928 - val_loss: 0.7253\n",
            "Epoch 16/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7697 - loss: 0.5663 - val_accuracy: 0.6928 - val_loss: 0.7261\n",
            "Epoch 17/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7808 - loss: 0.5415 - val_accuracy: 0.6940 - val_loss: 0.7300\n",
            "Epoch 18/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 754us/step - accuracy: 0.7934 - loss: 0.5161 - val_accuracy: 0.6932 - val_loss: 0.7371\n",
            "Epoch 19/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8056 - loss: 0.4899 - val_accuracy: 0.6940 - val_loss: 0.7469\n",
            "Epoch 20/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8182 - loss: 0.4631 - val_accuracy: 0.6916 - val_loss: 0.7605\n",
            "Epoch 21/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8322 - loss: 0.4356 - val_accuracy: 0.6870 - val_loss: 0.7772\n",
            "Epoch 22/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8466 - loss: 0.4074 - val_accuracy: 0.6857 - val_loss: 0.7969\n",
            "Epoch 23/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8607 - loss: 0.3791 - val_accuracy: 0.6825 - val_loss: 0.8209\n",
            "Epoch 24/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8747 - loss: 0.3506 - val_accuracy: 0.6785 - val_loss: 0.8463\n",
            "Epoch 25/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8888 - loss: 0.3224 - val_accuracy: 0.6751 - val_loss: 0.8738\n",
            "Epoch 26/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9013 - loss: 0.2947 - val_accuracy: 0.6746 - val_loss: 0.9032\n",
            "Epoch 27/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 786us/step - accuracy: 0.9127 - loss: 0.2676 - val_accuracy: 0.6720 - val_loss: 0.9344\n",
            "Epoch 28/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9241 - loss: 0.2415 - val_accuracy: 0.6703 - val_loss: 0.9689\n",
            "Epoch 29/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9350 - loss: 0.2165 - val_accuracy: 0.6700 - val_loss: 1.0042\n",
            "Epoch 30/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9454 - loss: 0.1927 - val_accuracy: 0.6684 - val_loss: 1.0412\n",
            "Epoch 31/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9553 - loss: 0.1703 - val_accuracy: 0.6670 - val_loss: 1.0800\n",
            "Epoch 32/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9632 - loss: 0.1496 - val_accuracy: 0.6682 - val_loss: 1.1184\n",
            "Epoch 33/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9709 - loss: 0.1307 - val_accuracy: 0.6676 - val_loss: 1.1581\n",
            "Epoch 34/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9767 - loss: 0.1136 - val_accuracy: 0.6676 - val_loss: 1.1984\n",
            "Epoch 35/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9819 - loss: 0.0985 - val_accuracy: 0.6676 - val_loss: 1.2401\n",
            "Epoch 36/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 978us/step - accuracy: 0.9863 - loss: 0.0852 - val_accuracy: 0.6659 - val_loss: 1.2790\n",
            "Epoch 37/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9902 - loss: 0.0737 - val_accuracy: 0.6650 - val_loss: 1.3185\n",
            "Epoch 38/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0638 - val_accuracy: 0.6654 - val_loss: 1.3569\n",
            "Epoch 39/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9942 - loss: 0.0553 - val_accuracy: 0.6653 - val_loss: 1.3933\n",
            "Epoch 40/40\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9956 - loss: 0.0479 - val_accuracy: 0.6670 - val_loss: 1.4285\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kc/dev/2249/CSI4506/Devoir3/venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5150 - loss: 1.0084 - val_accuracy: 0.6296 - val_loss: 0.8416\n",
            "Epoch 2/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6683 - loss: 0.7851 - val_accuracy: 0.6657 - val_loss: 0.7800\n",
            "Epoch 3/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6849 - loss: 0.7422 - val_accuracy: 0.6703 - val_loss: 0.7721\n",
            "Epoch 4/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6921 - loss: 0.7317 - val_accuracy: 0.6730 - val_loss: 0.7692\n",
            "Epoch 5/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6948 - loss: 0.7250 - val_accuracy: 0.6732 - val_loss: 0.7673\n",
            "Epoch 6/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6979 - loss: 0.7190 - val_accuracy: 0.6746 - val_loss: 0.7657\n",
            "Epoch 7/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7009 - loss: 0.7127 - val_accuracy: 0.6762 - val_loss: 0.7639\n",
            "Epoch 8/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7048 - loss: 0.7058 - val_accuracy: 0.6784 - val_loss: 0.7618\n",
            "Epoch 9/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7083 - loss: 0.6979 - val_accuracy: 0.6786 - val_loss: 0.7592\n",
            "Epoch 10/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7137 - loss: 0.6885 - val_accuracy: 0.6789 - val_loss: 0.7559\n",
            "Epoch 11/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7195 - loss: 0.6771 - val_accuracy: 0.6816 - val_loss: 0.7517\n",
            "Epoch 12/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7263 - loss: 0.6631 - val_accuracy: 0.6830 - val_loss: 0.7467\n",
            "Epoch 13/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 931us/step - accuracy: 0.7339 - loss: 0.6460 - val_accuracy: 0.6862 - val_loss: 0.7410\n",
            "Epoch 14/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7432 - loss: 0.6258 - val_accuracy: 0.6881 - val_loss: 0.7354\n",
            "Epoch 15/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7547 - loss: 0.6029 - val_accuracy: 0.6896 - val_loss: 0.7312\n",
            "Epoch 16/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7666 - loss: 0.5786 - val_accuracy: 0.6916 - val_loss: 0.7294\n",
            "Epoch 17/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7782 - loss: 0.5537 - val_accuracy: 0.6917 - val_loss: 0.7313\n",
            "Epoch 18/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7909 - loss: 0.5285 - val_accuracy: 0.6916 - val_loss: 0.7364\n",
            "Epoch 19/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8026 - loss: 0.5028 - val_accuracy: 0.6916 - val_loss: 0.7448\n",
            "Epoch 20/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8150 - loss: 0.4766 - val_accuracy: 0.6912 - val_loss: 0.7560\n",
            "Epoch 21/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 939us/step - accuracy: 0.8283 - loss: 0.4499 - val_accuracy: 0.6881 - val_loss: 0.7702\n",
            "Epoch 22/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8408 - loss: 0.4229 - val_accuracy: 0.6848 - val_loss: 0.7870\n",
            "Epoch 23/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8539 - loss: 0.3955 - val_accuracy: 0.6819 - val_loss: 0.8061\n",
            "Epoch 24/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8666 - loss: 0.3682 - val_accuracy: 0.6778 - val_loss: 0.8286\n",
            "Epoch 25/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8791 - loss: 0.3410 - val_accuracy: 0.6757 - val_loss: 0.8532\n",
            "Epoch 26/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8914 - loss: 0.3140 - val_accuracy: 0.6740 - val_loss: 0.8802\n",
            "Epoch 27/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9042 - loss: 0.2874 - val_accuracy: 0.6708 - val_loss: 0.9092\n",
            "Epoch 28/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.2615 - val_accuracy: 0.6704 - val_loss: 0.9418\n",
            "Epoch 29/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9268 - loss: 0.2364 - val_accuracy: 0.6673 - val_loss: 0.9764\n",
            "Epoch 30/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9368 - loss: 0.2123 - val_accuracy: 0.6650 - val_loss: 1.0129\n",
            "Epoch 31/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9472 - loss: 0.1893 - val_accuracy: 0.6627 - val_loss: 1.0522\n",
            "Epoch 32/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9554 - loss: 0.1678 - val_accuracy: 0.6631 - val_loss: 1.0930\n",
            "Epoch 33/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9645 - loss: 0.1477 - val_accuracy: 0.6622 - val_loss: 1.1353\n",
            "Epoch 34/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9713 - loss: 0.1293 - val_accuracy: 0.6612 - val_loss: 1.1792\n",
            "Epoch 35/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9773 - loss: 0.1126 - val_accuracy: 0.6599 - val_loss: 1.2210\n",
            "Epoch 36/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9825 - loss: 0.0978 - val_accuracy: 0.6593 - val_loss: 1.2641\n",
            "Epoch 37/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9870 - loss: 0.0848 - val_accuracy: 0.6585 - val_loss: 1.3052\n",
            "Epoch 38/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 967us/step - accuracy: 0.9901 - loss: 0.0735 - val_accuracy: 0.6581 - val_loss: 1.3453\n",
            "Epoch 39/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9924 - loss: 0.0636 - val_accuracy: 0.6591 - val_loss: 1.3841\n",
            "Epoch 40/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9944 - loss: 0.0552 - val_accuracy: 0.6587 - val_loss: 1.4214\n",
            "Epoch 41/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9958 - loss: 0.0481 - val_accuracy: 0.6565 - val_loss: 1.4570\n",
            "Epoch 42/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9970 - loss: 0.0420 - val_accuracy: 0.6581 - val_loss: 1.4902\n",
            "Epoch 43/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9979 - loss: 0.0369 - val_accuracy: 0.6581 - val_loss: 1.5203\n",
            "Epoch 44/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9982 - loss: 0.0325 - val_accuracy: 0.6572 - val_loss: 1.5498\n",
            "Epoch 45/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9988 - loss: 0.0288 - val_accuracy: 0.6574 - val_loss: 1.5757\n",
            "Epoch 46/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0256 - val_accuracy: 0.6580 - val_loss: 1.6007\n",
            "Epoch 47/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 913us/step - accuracy: 0.9995 - loss: 0.0229 - val_accuracy: 0.6572 - val_loss: 1.6231\n",
            "Epoch 48/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0206 - val_accuracy: 0.6581 - val_loss: 1.6452\n",
            "Epoch 49/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0187 - val_accuracy: 0.6588 - val_loss: 1.6659\n",
            "Epoch 50/50\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 0.0170 - val_accuracy: 0.6588 - val_loss: 1.6853\n"
          ]
        }
      ],
      "source": [
        "# Code cell\n",
        "histories[8] = create_model_with_hidden_layer(8,30)\n",
        "histories[16] = create_model_with_hidden_layer(16,30)\n",
        "histories[32] = create_model_with_hidden_layer(32,30)\n",
        "histories[64] = create_model_with_hidden_layer(64,30)\n",
        "histories[128] = create_model_with_hidden_layer(128,30)\n",
        "histories[256] = create_model_with_hidden_layer(256,40)\n",
        "histories[512] = create_model_with_hidden_layer(512,50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x1500 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot histories 1, 4, 16, 64, 256 on a single graph\n",
        "plt.figure(figsize=(15,15))\n",
        "scores = [\"loss\", \"accuracy\", \"val_loss\", \"val_accuracy\"]\n",
        "model_sizes = [1, 4, 128, 512]\n",
        "for i, score in enumerate(scores):\n",
        "    plt.subplot(2,2,i+1)\n",
        "    plt.ylim(0, 2)\n",
        "    plt.grid(True)\n",
        "    for model_size in model_sizes:\n",
        "        plt.plot(histories[model_size].history[score], label=f\"{model_size}\", marker=\".\", linestyle=\"--\")\n",
        "        plt.xlabel(\"Epochs\")\n",
        "        plt.ylabel(score)\n",
        "        plt.title(f\"{score}\")\n",
        "    plt.legend(loc=\"best\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Assurez-vous que le **nombre d'époques d'entraînement** est suffisant pour **observer une augmentation de la perte de validation**. **Conseil** : Lors du développement du modèle, commencez avec un petit nombre d'époques, comme 5 ou 10. Une fois que le modèle semble bien fonctionner, testez avec des valeurs plus importantes, comme 40 ou 80 époques, ce qui s'est avéré raisonnable dans nos tests. En fonction de vos observations, envisagez de mener des expériences supplémentaires, si nécessaire. Combien d'époques ont finalement été nécessaires ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Code cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> ## Observations from varying number of nodes in hidden layer\n",
        ">\n",
        "> After having plotted the accuracy and loss of each model for both the training and validation data, we can see that as from 4 nodes and upwards the scores of the model barely change. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Variation du nombre de couches**.\n",
        "\n",
        "    - Réalisez des expériences similaires à celles décrites ci-dessus, mais cette fois en faisant varier le nombre de couches de 1 à 4. Documentez vos résultats."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Code cell\n",
        "histories2 = {}\n",
        "def create_model(num_layers, pyramid=False, starting_size=32):\n",
        "    print(f\"Creating model with {num_layers} layers\")\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Dense(462, input_dim=462, activation='relu'))\n",
        "    for i in range(num_layers):\n",
        "        model.add(tf.keras.layers.Dense(starting_size//2**(i)))\n",
        "    model.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
        "    \n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Combien de nœuds chaque couche devrait-elle contenir ? Testez au moins deux scénarios. Traditionnellement, une stratégie courante consistait à diminuer le nombre de nœuds de la couche d'entrée à la couche de sortie, souvent en divisant par deux, pour créer une structure en pyramide. Cependant, l'expérience récente suggère que le maintien d'un nombre constant de nœuds dans toutes les couches peut également bien fonctionner. Décrivez vos observations. Il est acceptable que les deux stratégies produisent des résultats similaires en termes de performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Code cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kc/dev/2249/CSI4506/Devoir3/venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4780 - loss: 1.0304 - val_accuracy: 0.5847 - val_loss: 0.8799\n",
            "Epoch 2/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6404 - loss: 0.8186 - val_accuracy: 0.6627 - val_loss: 0.7849\n",
            "Epoch 3/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6837 - loss: 0.7458 - val_accuracy: 0.6696 - val_loss: 0.7735\n",
            "Epoch 4/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6904 - loss: 0.7302 - val_accuracy: 0.6699 - val_loss: 0.7695\n",
            "Epoch 5/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6968 - loss: 0.7200 - val_accuracy: 0.6705 - val_loss: 0.7666\n",
            "Epoch 6/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7015 - loss: 0.7100 - val_accuracy: 0.6727 - val_loss: 0.7633\n",
            "Epoch 7/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7066 - loss: 0.6984 - val_accuracy: 0.6736 - val_loss: 0.7591\n",
            "Epoch 8/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7133 - loss: 0.6836 - val_accuracy: 0.6770 - val_loss: 0.7536\n",
            "Epoch 9/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7223 - loss: 0.6638 - val_accuracy: 0.6808 - val_loss: 0.7469\n",
            "Epoch 10/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 924us/step - accuracy: 0.7337 - loss: 0.6383 - val_accuracy: 0.6824 - val_loss: 0.7419\n",
            "Epoch 11/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7494 - loss: 0.6089 - val_accuracy: 0.6851 - val_loss: 0.7426\n",
            "Epoch 12/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7628 - loss: 0.5781 - val_accuracy: 0.6848 - val_loss: 0.7516\n",
            "Epoch 13/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7754 - loss: 0.5460 - val_accuracy: 0.6790 - val_loss: 0.7683\n",
            "Epoch 14/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7913 - loss: 0.5119 - val_accuracy: 0.6740 - val_loss: 0.7934\n",
            "Epoch 15/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8091 - loss: 0.4757 - val_accuracy: 0.6699 - val_loss: 0.8306\n",
            "Epoch 16/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8277 - loss: 0.4373 - val_accuracy: 0.6645 - val_loss: 0.8829\n",
            "Epoch 17/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8466 - loss: 0.3977 - val_accuracy: 0.6611 - val_loss: 0.9433\n",
            "Epoch 18/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8654 - loss: 0.3575 - val_accuracy: 0.6562 - val_loss: 1.0195\n",
            "Epoch 19/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 906us/step - accuracy: 0.8841 - loss: 0.3162 - val_accuracy: 0.6496 - val_loss: 1.1178\n",
            "Epoch 20/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9039 - loss: 0.2750 - val_accuracy: 0.6460 - val_loss: 1.2300\n",
            "Epoch 21/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9223 - loss: 0.2341 - val_accuracy: 0.6418 - val_loss: 1.3557\n",
            "Epoch 22/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9237 - loss: 0.2224 - val_accuracy: 0.6265 - val_loss: 1.5514\n",
            "Epoch 23/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9219 - loss: 0.2158 - val_accuracy: 0.6441 - val_loss: 1.5576\n",
            "Epoch 24/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9204 - loss: 0.2105 - val_accuracy: 0.6318 - val_loss: 1.6585\n",
            "Epoch 25/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9469 - loss: 0.1519 - val_accuracy: 0.6461 - val_loss: 1.6968\n",
            "Epoch 26/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9597 - loss: 0.1213 - val_accuracy: 0.6403 - val_loss: 1.8480\n",
            "Epoch 27/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9715 - loss: 0.0908 - val_accuracy: 0.6512 - val_loss: 1.9748\n",
            "Epoch 28/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 934us/step - accuracy: 0.9745 - loss: 0.0800 - val_accuracy: 0.6549 - val_loss: 2.0680\n",
            "Epoch 29/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9530 - loss: 0.1347 - val_accuracy: 0.6400 - val_loss: 2.1733\n",
            "Epoch 30/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9436 - loss: 0.1469 - val_accuracy: 0.6407 - val_loss: 2.1346\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kc/dev/2249/CSI4506/Devoir3/venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4371 - loss: 1.0439 - val_accuracy: 0.5663 - val_loss: 0.9231\n",
            "Epoch 2/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6179 - loss: 0.8499 - val_accuracy: 0.6549 - val_loss: 0.7888\n",
            "Epoch 3/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6830 - loss: 0.7485 - val_accuracy: 0.6638 - val_loss: 0.7728\n",
            "Epoch 4/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6915 - loss: 0.7302 - val_accuracy: 0.6686 - val_loss: 0.7688\n",
            "Epoch 5/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 889us/step - accuracy: 0.6955 - loss: 0.7203 - val_accuracy: 0.6712 - val_loss: 0.7662\n",
            "Epoch 6/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7008 - loss: 0.7108 - val_accuracy: 0.6727 - val_loss: 0.7633\n",
            "Epoch 7/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7053 - loss: 0.6998 - val_accuracy: 0.6747 - val_loss: 0.7602\n",
            "Epoch 8/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7131 - loss: 0.6859 - val_accuracy: 0.6765 - val_loss: 0.7557\n",
            "Epoch 9/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7222 - loss: 0.6672 - val_accuracy: 0.6821 - val_loss: 0.7495\n",
            "Epoch 10/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7338 - loss: 0.6421 - val_accuracy: 0.6835 - val_loss: 0.7437\n",
            "Epoch 11/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7467 - loss: 0.6115 - val_accuracy: 0.6902 - val_loss: 0.7431\n",
            "Epoch 12/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7622 - loss: 0.5792 - val_accuracy: 0.6931 - val_loss: 0.7488\n",
            "Epoch 13/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 944us/step - accuracy: 0.7781 - loss: 0.5459 - val_accuracy: 0.6923 - val_loss: 0.7612\n",
            "Epoch 14/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7934 - loss: 0.5109 - val_accuracy: 0.6842 - val_loss: 0.7832\n",
            "Epoch 15/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8108 - loss: 0.4742 - val_accuracy: 0.6789 - val_loss: 0.8152\n",
            "Epoch 16/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8298 - loss: 0.4355 - val_accuracy: 0.6755 - val_loss: 0.8577\n",
            "Epoch 17/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8482 - loss: 0.3955 - val_accuracy: 0.6701 - val_loss: 0.9138\n",
            "Epoch 18/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8681 - loss: 0.3545 - val_accuracy: 0.6655 - val_loss: 0.9868\n",
            "Epoch 19/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8871 - loss: 0.3127 - val_accuracy: 0.6595 - val_loss: 1.0779\n",
            "Epoch 20/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9062 - loss: 0.2701 - val_accuracy: 0.6533 - val_loss: 1.1920\n",
            "Epoch 21/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9222 - loss: 0.2321 - val_accuracy: 0.6471 - val_loss: 1.3252\n",
            "Epoch 22/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 911us/step - accuracy: 0.9293 - loss: 0.2103 - val_accuracy: 0.6422 - val_loss: 1.4731\n",
            "Epoch 23/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9226 - loss: 0.2159 - val_accuracy: 0.6558 - val_loss: 1.5068\n",
            "Epoch 24/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9255 - loss: 0.2045 - val_accuracy: 0.6454 - val_loss: 1.5791\n",
            "Epoch 25/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9517 - loss: 0.1421 - val_accuracy: 0.6403 - val_loss: 1.7372\n",
            "Epoch 26/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9641 - loss: 0.1126 - val_accuracy: 0.6523 - val_loss: 1.7872\n",
            "Epoch 27/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9633 - loss: 0.1128 - val_accuracy: 0.6481 - val_loss: 1.8781\n",
            "Epoch 28/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9514 - loss: 0.1356 - val_accuracy: 0.6458 - val_loss: 1.9490\n",
            "Epoch 29/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9674 - loss: 0.0946 - val_accuracy: 0.6452 - val_loss: 2.0549\n",
            "Epoch 30/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9723 - loss: 0.0809 - val_accuracy: 0.6429 - val_loss: 2.1127\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kc/dev/2249/CSI4506/Devoir3/venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5055 - loss: 0.9901 - val_accuracy: 0.6400 - val_loss: 0.8100\n",
            "Epoch 2/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 960us/step - accuracy: 0.6775 - loss: 0.7646 - val_accuracy: 0.6678 - val_loss: 0.7789\n",
            "Epoch 3/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6914 - loss: 0.7358 - val_accuracy: 0.6718 - val_loss: 0.7733\n",
            "Epoch 4/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6946 - loss: 0.7245 - val_accuracy: 0.6724 - val_loss: 0.7703\n",
            "Epoch 5/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6998 - loss: 0.7147 - val_accuracy: 0.6740 - val_loss: 0.7677\n",
            "Epoch 6/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7052 - loss: 0.7038 - val_accuracy: 0.6757 - val_loss: 0.7646\n",
            "Epoch 7/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7121 - loss: 0.6904 - val_accuracy: 0.6765 - val_loss: 0.7606\n",
            "Epoch 8/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7203 - loss: 0.6727 - val_accuracy: 0.6770 - val_loss: 0.7555\n",
            "Epoch 9/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7326 - loss: 0.6487 - val_accuracy: 0.6797 - val_loss: 0.7515\n",
            "Epoch 10/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7461 - loss: 0.6183 - val_accuracy: 0.6773 - val_loss: 0.7537\n",
            "Epoch 11/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 882us/step - accuracy: 0.7600 - loss: 0.5849 - val_accuracy: 0.6762 - val_loss: 0.7657\n",
            "Epoch 12/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7750 - loss: 0.5512 - val_accuracy: 0.6722 - val_loss: 0.7857\n",
            "Epoch 13/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7916 - loss: 0.5159 - val_accuracy: 0.6676 - val_loss: 0.8146\n",
            "Epoch 14/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8079 - loss: 0.4790 - val_accuracy: 0.6631 - val_loss: 0.8555\n",
            "Epoch 15/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8270 - loss: 0.4403 - val_accuracy: 0.6589 - val_loss: 0.9084\n",
            "Epoch 16/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8458 - loss: 0.4004 - val_accuracy: 0.6534 - val_loss: 0.9720\n",
            "Epoch 17/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8653 - loss: 0.3592 - val_accuracy: 0.6515 - val_loss: 1.0469\n",
            "Epoch 18/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8833 - loss: 0.3174 - val_accuracy: 0.6457 - val_loss: 1.1466\n",
            "Epoch 19/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9036 - loss: 0.2756 - val_accuracy: 0.6469 - val_loss: 1.2406\n",
            "Epoch 20/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 883us/step - accuracy: 0.9160 - loss: 0.2409 - val_accuracy: 0.6377 - val_loss: 1.4098\n",
            "Epoch 21/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9058 - loss: 0.2575 - val_accuracy: 0.6385 - val_loss: 1.4317\n",
            "Epoch 22/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2332 - val_accuracy: 0.6566 - val_loss: 1.4307\n",
            "Epoch 23/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9399 - loss: 0.1742 - val_accuracy: 0.6493 - val_loss: 1.5638\n",
            "Epoch 24/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9571 - loss: 0.1334 - val_accuracy: 0.6450 - val_loss: 1.7503\n",
            "Epoch 25/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9628 - loss: 0.1205 - val_accuracy: 0.6507 - val_loss: 1.8318\n",
            "Epoch 26/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9660 - loss: 0.1070 - val_accuracy: 0.6373 - val_loss: 2.0358\n",
            "Epoch 27/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9491 - loss: 0.1475 - val_accuracy: 0.6471 - val_loss: 1.9924\n",
            "Epoch 28/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9544 - loss: 0.1247 - val_accuracy: 0.6275 - val_loss: 2.3431\n",
            "Epoch 29/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 930us/step - accuracy: 0.9697 - loss: 0.0837 - val_accuracy: 0.6427 - val_loss: 2.3339\n",
            "Epoch 30/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9790 - loss: 0.0642 - val_accuracy: 0.6600 - val_loss: 2.1335\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kc/dev/2249/CSI4506/Devoir3/venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4289 - loss: 1.0645 - val_accuracy: 0.5678 - val_loss: 0.9830\n",
            "Epoch 2/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5964 - loss: 0.9127 - val_accuracy: 0.6213 - val_loss: 0.8425\n",
            "Epoch 3/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6638 - loss: 0.7856 - val_accuracy: 0.6642 - val_loss: 0.7788\n",
            "Epoch 4/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6879 - loss: 0.7378 - val_accuracy: 0.6711 - val_loss: 0.7716\n",
            "Epoch 5/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6932 - loss: 0.7254 - val_accuracy: 0.6716 - val_loss: 0.7684\n",
            "Epoch 6/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6977 - loss: 0.7161 - val_accuracy: 0.6742 - val_loss: 0.7658\n",
            "Epoch 7/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7019 - loss: 0.7064 - val_accuracy: 0.6757 - val_loss: 0.7633\n",
            "Epoch 8/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7078 - loss: 0.6949 - val_accuracy: 0.6744 - val_loss: 0.7601\n",
            "Epoch 9/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7149 - loss: 0.6800 - val_accuracy: 0.6750 - val_loss: 0.7562\n",
            "Epoch 10/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7237 - loss: 0.6599 - val_accuracy: 0.6800 - val_loss: 0.7520\n",
            "Epoch 11/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7365 - loss: 0.6335 - val_accuracy: 0.6796 - val_loss: 0.7496\n",
            "Epoch 12/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7513 - loss: 0.6027 - val_accuracy: 0.6798 - val_loss: 0.7521\n",
            "Epoch 13/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7671 - loss: 0.5701 - val_accuracy: 0.6776 - val_loss: 0.7610\n",
            "Epoch 14/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1000us/step - accuracy: 0.7833 - loss: 0.5361 - val_accuracy: 0.6753 - val_loss: 0.7769\n",
            "Epoch 15/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8004 - loss: 0.5001 - val_accuracy: 0.6731 - val_loss: 0.8019\n",
            "Epoch 16/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8178 - loss: 0.4622 - val_accuracy: 0.6715 - val_loss: 0.8371\n",
            "Epoch 17/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8357 - loss: 0.4226 - val_accuracy: 0.6699 - val_loss: 0.8820\n",
            "Epoch 18/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8547 - loss: 0.3814 - val_accuracy: 0.6637 - val_loss: 0.9413\n",
            "Epoch 19/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8746 - loss: 0.3400 - val_accuracy: 0.6572 - val_loss: 1.0182\n",
            "Epoch 20/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8943 - loss: 0.2983 - val_accuracy: 0.6542 - val_loss: 1.1080\n",
            "Epoch 21/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9112 - loss: 0.2566 - val_accuracy: 0.6493 - val_loss: 1.2117\n",
            "Epoch 22/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9229 - loss: 0.2296 - val_accuracy: 0.6476 - val_loss: 1.3131\n",
            "Epoch 23/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9174 - loss: 0.2348 - val_accuracy: 0.6461 - val_loss: 1.3751\n",
            "Epoch 24/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9247 - loss: 0.2065 - val_accuracy: 0.6422 - val_loss: 1.4576\n",
            "Epoch 25/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9422 - loss: 0.1655 - val_accuracy: 0.6311 - val_loss: 1.5999\n",
            "Epoch 26/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9581 - loss: 0.1294 - val_accuracy: 0.6415 - val_loss: 1.7007\n",
            "Epoch 27/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9701 - loss: 0.0971 - val_accuracy: 0.6437 - val_loss: 1.8767\n",
            "Epoch 28/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9746 - loss: 0.0825 - val_accuracy: 0.6244 - val_loss: 2.1405\n",
            "Epoch 29/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 991us/step - accuracy: 0.9180 - loss: 0.2413 - val_accuracy: 0.6394 - val_loss: 1.9695\n",
            "Epoch 30/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9459 - loss: 0.1416 - val_accuracy: 0.6373 - val_loss: 2.0922\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kc/dev/2249/CSI4506/Devoir3/venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5097 - loss: 0.9982 - val_accuracy: 0.6484 - val_loss: 0.8064\n",
            "Epoch 2/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6788 - loss: 0.7612 - val_accuracy: 0.6655 - val_loss: 0.7789\n",
            "Epoch 3/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6907 - loss: 0.7351 - val_accuracy: 0.6682 - val_loss: 0.7739\n",
            "Epoch 4/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6950 - loss: 0.7239 - val_accuracy: 0.6680 - val_loss: 0.7709\n",
            "Epoch 5/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7000 - loss: 0.7138 - val_accuracy: 0.6705 - val_loss: 0.7680\n",
            "Epoch 6/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7057 - loss: 0.7026 - val_accuracy: 0.6744 - val_loss: 0.7643\n",
            "Epoch 7/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 978us/step - accuracy: 0.7119 - loss: 0.6888 - val_accuracy: 0.6767 - val_loss: 0.7593\n",
            "Epoch 8/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7210 - loss: 0.6706 - val_accuracy: 0.6797 - val_loss: 0.7529\n",
            "Epoch 9/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7326 - loss: 0.6465 - val_accuracy: 0.6836 - val_loss: 0.7461\n",
            "Epoch 10/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7449 - loss: 0.6172 - val_accuracy: 0.6865 - val_loss: 0.7442\n",
            "Epoch 11/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7601 - loss: 0.5857 - val_accuracy: 0.6851 - val_loss: 0.7487\n",
            "Epoch 12/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7755 - loss: 0.5531 - val_accuracy: 0.6828 - val_loss: 0.7609\n",
            "Epoch 13/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7918 - loss: 0.5184 - val_accuracy: 0.6809 - val_loss: 0.7832\n",
            "Epoch 14/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8090 - loss: 0.4816 - val_accuracy: 0.6746 - val_loss: 0.8162\n",
            "Epoch 15/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8252 - loss: 0.4431 - val_accuracy: 0.6696 - val_loss: 0.8591\n",
            "Epoch 16/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8427 - loss: 0.4025 - val_accuracy: 0.6637 - val_loss: 0.9104\n",
            "Epoch 17/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8627 - loss: 0.3610 - val_accuracy: 0.6585 - val_loss: 0.9731\n",
            "Epoch 18/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8843 - loss: 0.3180 - val_accuracy: 0.6538 - val_loss: 1.0518\n",
            "Epoch 19/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9052 - loss: 0.2744 - val_accuracy: 0.6503 - val_loss: 1.1468\n",
            "Epoch 20/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9243 - loss: 0.2325 - val_accuracy: 0.6469 - val_loss: 1.2606\n",
            "Epoch 21/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9364 - loss: 0.1998 - val_accuracy: 0.6450 - val_loss: 1.3683\n",
            "Epoch 22/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9282 - loss: 0.2058 - val_accuracy: 0.6458 - val_loss: 1.4697\n",
            "Epoch 23/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9291 - loss: 0.1972 - val_accuracy: 0.6412 - val_loss: 1.5764\n",
            "Epoch 24/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9443 - loss: 0.1567 - val_accuracy: 0.6439 - val_loss: 1.6098\n",
            "Epoch 25/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9640 - loss: 0.1112 - val_accuracy: 0.6410 - val_loss: 1.8255\n",
            "Epoch 26/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9704 - loss: 0.0970 - val_accuracy: 0.6354 - val_loss: 2.0353\n",
            "Epoch 27/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9749 - loss: 0.0786 - val_accuracy: 0.6392 - val_loss: 2.0934\n",
            "Epoch 28/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9766 - loss: 0.0739 - val_accuracy: 0.6404 - val_loss: 2.1839\n",
            "Epoch 29/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9381 - loss: 0.1682 - val_accuracy: 0.6385 - val_loss: 2.2064\n",
            "Epoch 30/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9519 - loss: 0.1306 - val_accuracy: 0.6441 - val_loss: 2.2531\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kc/dev/2249/CSI4506/Devoir3/venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4788 - loss: 1.0253 - val_accuracy: 0.6260 - val_loss: 0.8318\n",
            "Epoch 2/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6711 - loss: 0.7759 - val_accuracy: 0.6623 - val_loss: 0.7810\n",
            "Epoch 3/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6870 - loss: 0.7396 - val_accuracy: 0.6666 - val_loss: 0.7744\n",
            "Epoch 4/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6918 - loss: 0.7287 - val_accuracy: 0.6686 - val_loss: 0.7714\n",
            "Epoch 5/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6964 - loss: 0.7201 - val_accuracy: 0.6720 - val_loss: 0.7692\n",
            "Epoch 6/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7004 - loss: 0.7111 - val_accuracy: 0.6743 - val_loss: 0.7668\n",
            "Epoch 7/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7059 - loss: 0.7007 - val_accuracy: 0.6746 - val_loss: 0.7640\n",
            "Epoch 8/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7123 - loss: 0.6875 - val_accuracy: 0.6754 - val_loss: 0.7612\n",
            "Epoch 9/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7210 - loss: 0.6699 - val_accuracy: 0.6754 - val_loss: 0.7575\n",
            "Epoch 10/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 980us/step - accuracy: 0.7318 - loss: 0.6457 - val_accuracy: 0.6762 - val_loss: 0.7558\n",
            "Epoch 11/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7463 - loss: 0.6146 - val_accuracy: 0.6786 - val_loss: 0.7593\n",
            "Epoch 12/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7614 - loss: 0.5795 - val_accuracy: 0.6803 - val_loss: 0.7699\n",
            "Epoch 13/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7790 - loss: 0.5431 - val_accuracy: 0.6793 - val_loss: 0.7884\n",
            "Epoch 14/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7970 - loss: 0.5051 - val_accuracy: 0.6781 - val_loss: 0.8187\n",
            "Epoch 15/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8158 - loss: 0.4656 - val_accuracy: 0.6766 - val_loss: 0.8575\n",
            "Epoch 16/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8363 - loss: 0.4246 - val_accuracy: 0.6749 - val_loss: 0.9081\n",
            "Epoch 17/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8546 - loss: 0.3828 - val_accuracy: 0.6689 - val_loss: 0.9739\n",
            "Epoch 18/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 966us/step - accuracy: 0.8747 - loss: 0.3400 - val_accuracy: 0.6607 - val_loss: 1.0607\n",
            "Epoch 19/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8927 - loss: 0.2971 - val_accuracy: 0.6557 - val_loss: 1.1613\n",
            "Epoch 20/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2553 - val_accuracy: 0.6512 - val_loss: 1.2669\n",
            "Epoch 21/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9275 - loss: 0.2206 - val_accuracy: 0.6418 - val_loss: 1.4012\n",
            "Epoch 22/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9223 - loss: 0.2231 - val_accuracy: 0.6512 - val_loss: 1.3940\n",
            "Epoch 23/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9226 - loss: 0.2144 - val_accuracy: 0.6496 - val_loss: 1.5267\n",
            "Epoch 24/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9458 - loss: 0.1568 - val_accuracy: 0.6551 - val_loss: 1.6125\n",
            "Epoch 25/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9613 - loss: 0.1220 - val_accuracy: 0.6518 - val_loss: 1.7566\n",
            "Epoch 26/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9700 - loss: 0.0997 - val_accuracy: 0.6499 - val_loss: 1.9448\n",
            "Epoch 27/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9561 - loss: 0.1282 - val_accuracy: 0.6526 - val_loss: 1.8742\n",
            "Epoch 28/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9435 - loss: 0.1527 - val_accuracy: 0.6530 - val_loss: 1.9804\n",
            "Epoch 29/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9566 - loss: 0.1199 - val_accuracy: 0.6477 - val_loss: 2.1340\n",
            "Epoch 30/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9746 - loss: 0.0751 - val_accuracy: 0.6489 - val_loss: 2.1081\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kc/dev/2249/CSI4506/Devoir3/venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4042 - loss: 1.0674 - val_accuracy: 0.4207 - val_loss: 1.0532\n",
            "Epoch 2/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4355 - loss: 1.0067 - val_accuracy: 0.4864 - val_loss: 0.9634\n",
            "Epoch 3/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5083 - loss: 0.9287 - val_accuracy: 0.5263 - val_loss: 0.9321\n",
            "Epoch 4/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5647 - loss: 0.8925 - val_accuracy: 0.5531 - val_loss: 0.9091\n",
            "Epoch 5/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5855 - loss: 0.8692 - val_accuracy: 0.5636 - val_loss: 0.8967\n",
            "Epoch 6/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5952 - loss: 0.8535 - val_accuracy: 0.5721 - val_loss: 0.8872\n",
            "Epoch 7/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6055 - loss: 0.8375 - val_accuracy: 0.5820 - val_loss: 0.8762\n",
            "Epoch 8/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6204 - loss: 0.8153 - val_accuracy: 0.5901 - val_loss: 0.8627\n",
            "Epoch 9/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6429 - loss: 0.7817 - val_accuracy: 0.5995 - val_loss: 0.8509\n",
            "Epoch 10/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6702 - loss: 0.7413 - val_accuracy: 0.6090 - val_loss: 0.8450\n",
            "Epoch 11/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6895 - loss: 0.7013 - val_accuracy: 0.6137 - val_loss: 0.8479\n",
            "Epoch 12/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7079 - loss: 0.6613 - val_accuracy: 0.6133 - val_loss: 0.8628\n",
            "Epoch 13/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7295 - loss: 0.6217 - val_accuracy: 0.6138 - val_loss: 0.8891\n",
            "Epoch 14/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7500 - loss: 0.5812 - val_accuracy: 0.6111 - val_loss: 0.9299\n",
            "Epoch 15/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7706 - loss: 0.5404 - val_accuracy: 0.6017 - val_loss: 0.9933\n",
            "Epoch 16/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7910 - loss: 0.4999 - val_accuracy: 0.5947 - val_loss: 1.0785\n",
            "Epoch 17/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8102 - loss: 0.4612 - val_accuracy: 0.5906 - val_loss: 1.1829\n",
            "Epoch 18/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8211 - loss: 0.4375 - val_accuracy: 0.5765 - val_loss: 1.3465\n",
            "Epoch 19/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8219 - loss: 0.4300 - val_accuracy: 0.5891 - val_loss: 1.2757\n",
            "Epoch 20/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8439 - loss: 0.3869 - val_accuracy: 0.5863 - val_loss: 1.3832\n",
            "Epoch 21/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 958us/step - accuracy: 0.8509 - loss: 0.3643 - val_accuracy: 0.5959 - val_loss: 1.3177\n",
            "Epoch 22/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8662 - loss: 0.3407 - val_accuracy: 0.5673 - val_loss: 1.6999\n",
            "Epoch 23/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8754 - loss: 0.3224 - val_accuracy: 0.5959 - val_loss: 1.4492\n",
            "Epoch 24/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8897 - loss: 0.2995 - val_accuracy: 0.5975 - val_loss: 1.4855\n",
            "Epoch 25/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8963 - loss: 0.2784 - val_accuracy: 0.5786 - val_loss: 1.7961\n",
            "Epoch 26/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9056 - loss: 0.2627 - val_accuracy: 0.4866 - val_loss: 2.6956\n",
            "Epoch 27/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8981 - loss: 0.2860 - val_accuracy: 0.4111 - val_loss: 5.2201\n",
            "Epoch 28/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9103 - loss: 0.2576 - val_accuracy: 0.5933 - val_loss: 1.8111\n",
            "Epoch 29/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 958us/step - accuracy: 0.9367 - loss: 0.1872 - val_accuracy: 0.6025 - val_loss: 1.7795\n",
            "Epoch 30/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9462 - loss: 0.1749 - val_accuracy: 0.5983 - val_loss: 1.8355\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kc/dev/2249/CSI4506/Devoir3/venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4864 - loss: 1.0187 - val_accuracy: 0.6197 - val_loss: 0.8451\n",
            "Epoch 2/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6668 - loss: 0.7851 - val_accuracy: 0.6695 - val_loss: 0.7797\n",
            "Epoch 3/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6878 - loss: 0.7396 - val_accuracy: 0.6716 - val_loss: 0.7734\n",
            "Epoch 4/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6942 - loss: 0.7260 - val_accuracy: 0.6712 - val_loss: 0.7703\n",
            "Epoch 5/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6990 - loss: 0.7147 - val_accuracy: 0.6735 - val_loss: 0.7674\n",
            "Epoch 6/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7063 - loss: 0.7023 - val_accuracy: 0.6755 - val_loss: 0.7639\n",
            "Epoch 7/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 959us/step - accuracy: 0.7146 - loss: 0.6864 - val_accuracy: 0.6782 - val_loss: 0.7594\n",
            "Epoch 8/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7240 - loss: 0.6644 - val_accuracy: 0.6824 - val_loss: 0.7547\n",
            "Epoch 9/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7365 - loss: 0.6344 - val_accuracy: 0.6869 - val_loss: 0.7549\n",
            "Epoch 10/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7521 - loss: 0.5994 - val_accuracy: 0.6869 - val_loss: 0.7630\n",
            "Epoch 11/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7696 - loss: 0.5620 - val_accuracy: 0.6861 - val_loss: 0.7822\n",
            "Epoch 12/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7894 - loss: 0.5224 - val_accuracy: 0.6817 - val_loss: 0.8169\n",
            "Epoch 13/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8085 - loss: 0.4804 - val_accuracy: 0.6695 - val_loss: 0.8674\n",
            "Epoch 14/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8276 - loss: 0.4362 - val_accuracy: 0.6639 - val_loss: 0.9266\n",
            "Epoch 15/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8497 - loss: 0.3907 - val_accuracy: 0.6581 - val_loss: 1.0096\n",
            "Epoch 16/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8706 - loss: 0.3450 - val_accuracy: 0.6553 - val_loss: 1.1151\n",
            "Epoch 17/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8905 - loss: 0.3011 - val_accuracy: 0.6518 - val_loss: 1.2396\n",
            "Epoch 18/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8968 - loss: 0.2834 - val_accuracy: 0.6383 - val_loss: 1.3857\n",
            "Epoch 19/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9034 - loss: 0.2643 - val_accuracy: 0.6554 - val_loss: 1.3973\n",
            "Epoch 20/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9234 - loss: 0.2124 - val_accuracy: 0.6423 - val_loss: 1.5968\n",
            "Epoch 21/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9324 - loss: 0.1876 - val_accuracy: 0.6520 - val_loss: 1.6359\n",
            "Epoch 22/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9326 - loss: 0.1817 - val_accuracy: 0.6471 - val_loss: 1.7093\n",
            "Epoch 23/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9394 - loss: 0.1604 - val_accuracy: 0.6541 - val_loss: 1.8835\n",
            "Epoch 24/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9496 - loss: 0.1361 - val_accuracy: 0.6488 - val_loss: 2.1056\n",
            "Epoch 25/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9555 - loss: 0.1230 - val_accuracy: 0.6542 - val_loss: 2.0915\n",
            "Epoch 26/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9600 - loss: 0.1086 - val_accuracy: 0.6515 - val_loss: 2.2190\n",
            "Epoch 27/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9650 - loss: 0.0942 - val_accuracy: 0.6489 - val_loss: 2.2923\n",
            "Epoch 28/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9702 - loss: 0.0817 - val_accuracy: 0.6422 - val_loss: 2.7659\n",
            "Epoch 29/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9703 - loss: 0.0820 - val_accuracy: 0.6547 - val_loss: 2.5947\n",
            "Epoch 30/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9671 - loss: 0.0933 - val_accuracy: 0.6553 - val_loss: 2.5352\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kc/dev/2249/CSI4506/Devoir3/venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.4653 - loss: 1.0376 - val_accuracy: 0.6103 - val_loss: 0.8611\n",
            "Epoch 2/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6542 - loss: 0.8006 - val_accuracy: 0.6666 - val_loss: 0.7814\n",
            "Epoch 3/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6872 - loss: 0.7416 - val_accuracy: 0.6695 - val_loss: 0.7733\n",
            "Epoch 4/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6939 - loss: 0.7270 - val_accuracy: 0.6716 - val_loss: 0.7695\n",
            "Epoch 5/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6998 - loss: 0.7155 - val_accuracy: 0.6746 - val_loss: 0.7658\n",
            "Epoch 6/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7061 - loss: 0.7029 - val_accuracy: 0.6751 - val_loss: 0.7614\n",
            "Epoch 7/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7140 - loss: 0.6868 - val_accuracy: 0.6805 - val_loss: 0.7555\n",
            "Epoch 8/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7243 - loss: 0.6646 - val_accuracy: 0.6824 - val_loss: 0.7502\n",
            "Epoch 9/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7370 - loss: 0.6361 - val_accuracy: 0.6855 - val_loss: 0.7498\n",
            "Epoch 10/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 939us/step - accuracy: 0.7523 - loss: 0.6041 - val_accuracy: 0.6830 - val_loss: 0.7561\n",
            "Epoch 11/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7679 - loss: 0.5696 - val_accuracy: 0.6831 - val_loss: 0.7708\n",
            "Epoch 12/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7847 - loss: 0.5324 - val_accuracy: 0.6817 - val_loss: 0.7948\n",
            "Epoch 13/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8013 - loss: 0.4927 - val_accuracy: 0.6758 - val_loss: 0.8309\n",
            "Epoch 14/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8208 - loss: 0.4503 - val_accuracy: 0.6736 - val_loss: 0.8793\n",
            "Epoch 15/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8415 - loss: 0.4065 - val_accuracy: 0.6691 - val_loss: 0.9460\n",
            "Epoch 16/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8629 - loss: 0.3616 - val_accuracy: 0.6651 - val_loss: 1.0374\n",
            "Epoch 17/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8836 - loss: 0.3170 - val_accuracy: 0.6618 - val_loss: 1.1373\n",
            "Epoch 18/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8964 - loss: 0.2848 - val_accuracy: 0.6554 - val_loss: 1.2401\n",
            "Epoch 19/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9007 - loss: 0.2696 - val_accuracy: 0.6557 - val_loss: 1.3408\n",
            "Epoch 20/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9162 - loss: 0.2310 - val_accuracy: 0.6506 - val_loss: 1.4664\n",
            "Epoch 21/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9291 - loss: 0.1966 - val_accuracy: 0.6445 - val_loss: 1.6298\n",
            "Epoch 22/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9361 - loss: 0.1776 - val_accuracy: 0.6493 - val_loss: 1.7719\n",
            "Epoch 23/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9357 - loss: 0.1745 - val_accuracy: 0.6550 - val_loss: 1.7682\n",
            "Epoch 24/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9478 - loss: 0.1398 - val_accuracy: 0.6538 - val_loss: 1.9354\n",
            "Epoch 25/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9561 - loss: 0.1206 - val_accuracy: 0.6493 - val_loss: 2.1389\n",
            "Epoch 26/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9616 - loss: 0.1037 - val_accuracy: 0.6469 - val_loss: 2.1432\n",
            "Epoch 27/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9616 - loss: 0.1029 - val_accuracy: 0.6508 - val_loss: 2.2036\n",
            "Epoch 28/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9598 - loss: 0.1088 - val_accuracy: 0.6352 - val_loss: 2.3954\n",
            "Epoch 29/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9716 - loss: 0.0755 - val_accuracy: 0.6529 - val_loss: 2.3936\n",
            "Epoch 30/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9781 - loss: 0.0625 - val_accuracy: 0.6458 - val_loss: 2.5827\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kc/dev/2249/CSI4506/Devoir3/venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5145 - loss: 1.0108 - val_accuracy: 0.5900 - val_loss: 0.8978\n",
            "Epoch 2/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6166 - loss: 0.8690 - val_accuracy: 0.5958 - val_loss: 0.8859\n",
            "Epoch 3/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6226 - loss: 0.8543 - val_accuracy: 0.5983 - val_loss: 0.8828\n",
            "Epoch 4/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6266 - loss: 0.8453 - val_accuracy: 0.5978 - val_loss: 0.8803\n",
            "Epoch 5/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6312 - loss: 0.8361 - val_accuracy: 0.5982 - val_loss: 0.8778\n",
            "Epoch 6/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6356 - loss: 0.8248 - val_accuracy: 0.5989 - val_loss: 0.8753\n",
            "Epoch 7/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6417 - loss: 0.8095 - val_accuracy: 0.5974 - val_loss: 0.8741\n",
            "Epoch 8/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6508 - loss: 0.7883 - val_accuracy: 0.5936 - val_loss: 0.8781\n",
            "Epoch 9/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6608 - loss: 0.7618 - val_accuracy: 0.5904 - val_loss: 0.8889\n",
            "Epoch 10/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6727 - loss: 0.7328 - val_accuracy: 0.5901 - val_loss: 0.9065\n",
            "Epoch 11/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6829 - loss: 0.7021 - val_accuracy: 0.5893 - val_loss: 0.9283\n",
            "Epoch 12/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6961 - loss: 0.6704 - val_accuracy: 0.5867 - val_loss: 0.9605\n",
            "Epoch 13/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7092 - loss: 0.6380 - val_accuracy: 0.5819 - val_loss: 1.0075\n",
            "Epoch 14/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7205 - loss: 0.6054 - val_accuracy: 0.5784 - val_loss: 1.0753\n",
            "Epoch 15/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7327 - loss: 0.5733 - val_accuracy: 0.5680 - val_loss: 1.1875\n",
            "Epoch 16/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7469 - loss: 0.5430 - val_accuracy: 0.5622 - val_loss: 1.3454\n",
            "Epoch 17/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7500 - loss: 0.5322 - val_accuracy: 0.5557 - val_loss: 1.3914\n",
            "Epoch 18/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7496 - loss: 0.5297 - val_accuracy: 0.5574 - val_loss: 1.3926\n",
            "Epoch 19/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7647 - loss: 0.4976 - val_accuracy: 0.5684 - val_loss: 1.4056\n",
            "Epoch 20/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7776 - loss: 0.4785 - val_accuracy: 0.5704 - val_loss: 1.3941\n",
            "Epoch 21/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7831 - loss: 0.4598 - val_accuracy: 0.5110 - val_loss: 2.0163\n",
            "Epoch 22/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7895 - loss: 0.4497 - val_accuracy: 0.5716 - val_loss: 1.5206\n",
            "Epoch 23/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8018 - loss: 0.4276 - val_accuracy: 0.5518 - val_loss: 1.6978\n",
            "Epoch 24/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8129 - loss: 0.4115 - val_accuracy: 0.5763 - val_loss: 1.6504\n",
            "Epoch 25/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8185 - loss: 0.4002 - val_accuracy: 0.5705 - val_loss: 1.6632\n",
            "Epoch 26/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8270 - loss: 0.3845 - val_accuracy: 0.5597 - val_loss: 1.7745\n",
            "Epoch 27/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8432 - loss: 0.3588 - val_accuracy: 0.5659 - val_loss: 1.8125\n",
            "Epoch 28/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8465 - loss: 0.3524 - val_accuracy: 0.5669 - val_loss: 1.8614\n",
            "Epoch 29/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8528 - loss: 0.3427 - val_accuracy: 0.5607 - val_loss: 1.8745\n",
            "Epoch 30/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8611 - loss: 0.3217 - val_accuracy: 0.5676 - val_loss: 1.9934\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kc/dev/2249/CSI4506/Devoir3/venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.3993 - loss: 1.0630 - val_accuracy: 0.5052 - val_loss: 1.0155\n",
            "Epoch 2/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5903 - loss: 0.9233 - val_accuracy: 0.6581 - val_loss: 0.7943\n",
            "Epoch 3/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6806 - loss: 0.7534 - val_accuracy: 0.6700 - val_loss: 0.7780\n",
            "Epoch 4/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6904 - loss: 0.7345 - val_accuracy: 0.6705 - val_loss: 0.7738\n",
            "Epoch 5/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6961 - loss: 0.7242 - val_accuracy: 0.6718 - val_loss: 0.7712\n",
            "Epoch 6/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7010 - loss: 0.7144 - val_accuracy: 0.6723 - val_loss: 0.7689\n",
            "Epoch 7/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 951us/step - accuracy: 0.7067 - loss: 0.7034 - val_accuracy: 0.6732 - val_loss: 0.7667\n",
            "Epoch 8/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7124 - loss: 0.6894 - val_accuracy: 0.6773 - val_loss: 0.7640\n",
            "Epoch 9/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7217 - loss: 0.6699 - val_accuracy: 0.6801 - val_loss: 0.7608\n",
            "Epoch 10/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7353 - loss: 0.6419 - val_accuracy: 0.6804 - val_loss: 0.7609\n",
            "Epoch 11/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7508 - loss: 0.6068 - val_accuracy: 0.6851 - val_loss: 0.7669\n",
            "Epoch 12/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7688 - loss: 0.5693 - val_accuracy: 0.6828 - val_loss: 0.7829\n",
            "Epoch 13/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7873 - loss: 0.5296 - val_accuracy: 0.6793 - val_loss: 0.8190\n",
            "Epoch 14/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8061 - loss: 0.4874 - val_accuracy: 0.6708 - val_loss: 0.8727\n",
            "Epoch 15/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 999us/step - accuracy: 0.8268 - loss: 0.4434 - val_accuracy: 0.6618 - val_loss: 0.9571\n",
            "Epoch 16/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8484 - loss: 0.3975 - val_accuracy: 0.6526 - val_loss: 1.0659\n",
            "Epoch 17/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8688 - loss: 0.3504 - val_accuracy: 0.6425 - val_loss: 1.2092\n",
            "Epoch 18/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8903 - loss: 0.3044 - val_accuracy: 0.6380 - val_loss: 1.3712\n",
            "Epoch 19/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9052 - loss: 0.2682 - val_accuracy: 0.6310 - val_loss: 1.5114\n",
            "Epoch 20/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9030 - loss: 0.2621 - val_accuracy: 0.6333 - val_loss: 1.5866\n",
            "Epoch 21/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2369 - val_accuracy: 0.6331 - val_loss: 1.6369\n",
            "Epoch 22/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9319 - loss: 0.1832 - val_accuracy: 0.6450 - val_loss: 1.7506\n",
            "Epoch 23/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9360 - loss: 0.1742 - val_accuracy: 0.6178 - val_loss: 2.1323\n",
            "Epoch 24/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 948us/step - accuracy: 0.9424 - loss: 0.1590 - val_accuracy: 0.6255 - val_loss: 2.0826\n",
            "Epoch 25/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9460 - loss: 0.1431 - val_accuracy: 0.6431 - val_loss: 1.9423\n",
            "Epoch 26/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9515 - loss: 0.1324 - val_accuracy: 0.6531 - val_loss: 2.0776\n",
            "Epoch 27/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9639 - loss: 0.0980 - val_accuracy: 0.6441 - val_loss: 2.2639\n",
            "Epoch 28/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9591 - loss: 0.1058 - val_accuracy: 0.6406 - val_loss: 2.3089\n",
            "Epoch 29/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9627 - loss: 0.1094 - val_accuracy: 0.6349 - val_loss: 2.5028\n",
            "Epoch 30/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9694 - loss: 0.0835 - val_accuracy: 0.6491 - val_loss: 2.4158\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kc/dev/2249/CSI4506/Devoir3/venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5087 - loss: 1.0027 - val_accuracy: 0.6186 - val_loss: 0.8430\n",
            "Epoch 2/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 954us/step - accuracy: 0.6636 - loss: 0.7854 - val_accuracy: 0.6618 - val_loss: 0.7786\n",
            "Epoch 3/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6889 - loss: 0.7388 - val_accuracy: 0.6672 - val_loss: 0.7716\n",
            "Epoch 4/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6951 - loss: 0.7252 - val_accuracy: 0.6693 - val_loss: 0.7676\n",
            "Epoch 5/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7000 - loss: 0.7134 - val_accuracy: 0.6719 - val_loss: 0.7640\n",
            "Epoch 6/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7065 - loss: 0.6999 - val_accuracy: 0.6753 - val_loss: 0.7599\n",
            "Epoch 7/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7150 - loss: 0.6822 - val_accuracy: 0.6774 - val_loss: 0.7549\n",
            "Epoch 8/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7257 - loss: 0.6577 - val_accuracy: 0.6794 - val_loss: 0.7511\n",
            "Epoch 9/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7417 - loss: 0.6261 - val_accuracy: 0.6777 - val_loss: 0.7527\n",
            "Epoch 10/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7570 - loss: 0.5913 - val_accuracy: 0.6767 - val_loss: 0.7614\n",
            "Epoch 11/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7738 - loss: 0.5548 - val_accuracy: 0.6792 - val_loss: 0.7803\n",
            "Epoch 12/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7920 - loss: 0.5166 - val_accuracy: 0.6727 - val_loss: 0.8171\n",
            "Epoch 13/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8105 - loss: 0.4768 - val_accuracy: 0.6670 - val_loss: 0.8645\n",
            "Epoch 14/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8296 - loss: 0.4356 - val_accuracy: 0.6665 - val_loss: 0.9162\n",
            "Epoch 15/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8517 - loss: 0.3925 - val_accuracy: 0.6670 - val_loss: 0.9815\n",
            "Epoch 16/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8709 - loss: 0.3487 - val_accuracy: 0.6612 - val_loss: 1.0929\n",
            "Epoch 17/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8854 - loss: 0.3109 - val_accuracy: 0.6668 - val_loss: 1.1619\n",
            "Epoch 18/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8873 - loss: 0.3040 - val_accuracy: 0.6639 - val_loss: 1.2058\n",
            "Epoch 19/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 980us/step - accuracy: 0.9050 - loss: 0.2603 - val_accuracy: 0.6524 - val_loss: 1.3436\n",
            "Epoch 20/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9208 - loss: 0.2212 - val_accuracy: 0.6538 - val_loss: 1.5980\n",
            "Epoch 21/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9271 - loss: 0.2017 - val_accuracy: 0.6577 - val_loss: 1.6687\n",
            "Epoch 22/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9342 - loss: 0.1790 - val_accuracy: 0.6391 - val_loss: 1.7105\n",
            "Epoch 23/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9395 - loss: 0.1630 - val_accuracy: 0.6549 - val_loss: 1.8416\n",
            "Epoch 24/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9473 - loss: 0.1421 - val_accuracy: 0.6573 - val_loss: 1.8987\n",
            "Epoch 25/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9563 - loss: 0.1169 - val_accuracy: 0.6622 - val_loss: 1.9390\n",
            "Epoch 26/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9596 - loss: 0.1086 - val_accuracy: 0.6511 - val_loss: 2.1098\n",
            "Epoch 27/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 976us/step - accuracy: 0.9615 - loss: 0.1003 - val_accuracy: 0.6589 - val_loss: 2.1780\n",
            "Epoch 28/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9650 - loss: 0.0936 - val_accuracy: 0.6570 - val_loss: 2.3810\n",
            "Epoch 29/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9723 - loss: 0.0784 - val_accuracy: 0.6570 - val_loss: 2.3852\n",
            "Epoch 30/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9696 - loss: 0.0808 - val_accuracy: 0.6527 - val_loss: 2.4569\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kc/dev/2249/CSI4506/Devoir3/venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.4146 - loss: 1.0707 - val_accuracy: 0.5314 - val_loss: 1.0201\n",
            "Epoch 2/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5809 - loss: 0.9327 - val_accuracy: 0.5897 - val_loss: 0.8952\n",
            "Epoch 3/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6131 - loss: 0.8639 - val_accuracy: 0.5927 - val_loss: 0.8884\n",
            "Epoch 4/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6195 - loss: 0.8531 - val_accuracy: 0.5950 - val_loss: 0.8856\n",
            "Epoch 5/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6253 - loss: 0.8452 - val_accuracy: 0.5960 - val_loss: 0.8833\n",
            "Epoch 6/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.6291 - loss: 0.8368 - val_accuracy: 0.5966 - val_loss: 0.8809\n",
            "Epoch 7/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.6344 - loss: 0.8258 - val_accuracy: 0.5972 - val_loss: 0.8779\n",
            "Epoch 8/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6408 - loss: 0.8103 - val_accuracy: 0.5977 - val_loss: 0.8760\n",
            "Epoch 9/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6492 - loss: 0.7886 - val_accuracy: 0.5966 - val_loss: 0.8791\n",
            "Epoch 10/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6594 - loss: 0.7627 - val_accuracy: 0.5951 - val_loss: 0.8862\n",
            "Epoch 11/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.6715 - loss: 0.7349 - val_accuracy: 0.5929 - val_loss: 0.8990\n",
            "Epoch 12/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6828 - loss: 0.7061 - val_accuracy: 0.5923 - val_loss: 0.9177\n",
            "Epoch 13/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6944 - loss: 0.6760 - val_accuracy: 0.5937 - val_loss: 0.9450\n",
            "Epoch 14/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7067 - loss: 0.6454 - val_accuracy: 0.5894 - val_loss: 0.9920\n",
            "Epoch 15/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7180 - loss: 0.6138 - val_accuracy: 0.5859 - val_loss: 1.0585\n",
            "Epoch 16/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7284 - loss: 0.5816 - val_accuracy: 0.5773 - val_loss: 1.1725\n",
            "Epoch 17/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7363 - loss: 0.5567 - val_accuracy: 0.5781 - val_loss: 1.2093\n",
            "Epoch 18/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7392 - loss: 0.5446 - val_accuracy: 0.5777 - val_loss: 1.2516\n",
            "Epoch 19/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7448 - loss: 0.5285 - val_accuracy: 0.5682 - val_loss: 1.3863\n",
            "Epoch 20/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7488 - loss: 0.5108 - val_accuracy: 0.5744 - val_loss: 1.3435\n",
            "Epoch 21/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7620 - loss: 0.4798 - val_accuracy: 0.5717 - val_loss: 1.4118\n",
            "Epoch 22/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7701 - loss: 0.4679 - val_accuracy: 0.5333 - val_loss: 1.8046\n",
            "Epoch 23/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7689 - loss: 0.4783 - val_accuracy: 0.5704 - val_loss: 1.5304\n",
            "Epoch 24/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7887 - loss: 0.4383 - val_accuracy: 0.5588 - val_loss: 1.6368\n",
            "Epoch 25/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7999 - loss: 0.4193 - val_accuracy: 0.5514 - val_loss: 1.6620\n",
            "Epoch 26/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8053 - loss: 0.4138 - val_accuracy: 0.5632 - val_loss: 1.7124\n",
            "Epoch 27/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8156 - loss: 0.3983 - val_accuracy: 0.5644 - val_loss: 1.8257\n",
            "Epoch 28/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8217 - loss: 0.4004 - val_accuracy: 0.5601 - val_loss: 1.7987\n",
            "Epoch 29/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8322 - loss: 0.3704 - val_accuracy: 0.5558 - val_loss: 1.8216\n",
            "Epoch 30/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8422 - loss: 0.3603 - val_accuracy: 0.5485 - val_loss: 1.9506\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kc/dev/2249/CSI4506/Devoir3/venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4509 - loss: 1.0339 - val_accuracy: 0.5457 - val_loss: 0.9218\n",
            "Epoch 2/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5785 - loss: 0.8823 - val_accuracy: 0.5816 - val_loss: 0.8807\n",
            "Epoch 3/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6334 - loss: 0.8159 - val_accuracy: 0.6632 - val_loss: 0.7840\n",
            "Epoch 4/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6889 - loss: 0.7353 - val_accuracy: 0.6705 - val_loss: 0.7710\n",
            "Epoch 5/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6975 - loss: 0.7169 - val_accuracy: 0.6730 - val_loss: 0.7650\n",
            "Epoch 6/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7056 - loss: 0.7008 - val_accuracy: 0.6762 - val_loss: 0.7599\n",
            "Epoch 7/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7161 - loss: 0.6801 - val_accuracy: 0.6797 - val_loss: 0.7562\n",
            "Epoch 8/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7279 - loss: 0.6516 - val_accuracy: 0.6820 - val_loss: 0.7565\n",
            "Epoch 9/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7413 - loss: 0.6182 - val_accuracy: 0.6807 - val_loss: 0.7637\n",
            "Epoch 10/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7579 - loss: 0.5819 - val_accuracy: 0.6742 - val_loss: 0.7817\n",
            "Epoch 11/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7739 - loss: 0.5444 - val_accuracy: 0.6680 - val_loss: 0.8139\n",
            "Epoch 12/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7933 - loss: 0.5057 - val_accuracy: 0.6600 - val_loss: 0.8722\n",
            "Epoch 13/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8128 - loss: 0.4653 - val_accuracy: 0.6565 - val_loss: 0.9470\n",
            "Epoch 14/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8343 - loss: 0.4231 - val_accuracy: 0.6492 - val_loss: 1.0447\n",
            "Epoch 15/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8528 - loss: 0.3799 - val_accuracy: 0.6435 - val_loss: 1.1713\n",
            "Epoch 16/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8675 - loss: 0.3419 - val_accuracy: 0.6187 - val_loss: 1.4169\n",
            "Epoch 17/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8733 - loss: 0.3265 - val_accuracy: 0.6396 - val_loss: 1.3051\n",
            "Epoch 18/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8875 - loss: 0.2927 - val_accuracy: 0.6125 - val_loss: 1.5998\n",
            "Epoch 19/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.2472 - val_accuracy: 0.6384 - val_loss: 1.5091\n",
            "Epoch 20/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9162 - loss: 0.2311 - val_accuracy: 0.6205 - val_loss: 1.8416\n",
            "Epoch 21/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9197 - loss: 0.2147 - val_accuracy: 0.6241 - val_loss: 1.9006\n",
            "Epoch 22/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9302 - loss: 0.1815 - val_accuracy: 0.6076 - val_loss: 2.1744\n",
            "Epoch 23/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9395 - loss: 0.1629 - val_accuracy: 0.6473 - val_loss: 2.0248\n",
            "Epoch 24/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9436 - loss: 0.1509 - val_accuracy: 0.6515 - val_loss: 2.0516\n",
            "Epoch 25/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9465 - loss: 0.1411 - val_accuracy: 0.6477 - val_loss: 2.1168\n",
            "Epoch 26/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9600 - loss: 0.1137 - val_accuracy: 0.6475 - val_loss: 2.2912\n",
            "Epoch 27/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9656 - loss: 0.0957 - val_accuracy: 0.6429 - val_loss: 2.5365\n",
            "Epoch 28/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9653 - loss: 0.0944 - val_accuracy: 0.6453 - val_loss: 2.3755\n",
            "Epoch 29/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9660 - loss: 0.0900 - val_accuracy: 0.6414 - val_loss: 2.5238\n",
            "Epoch 30/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9737 - loss: 0.0707 - val_accuracy: 0.6480 - val_loss: 2.6978\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kc/dev/2249/CSI4506/Devoir3/venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5133 - loss: 0.9977 - val_accuracy: 0.5887 - val_loss: 0.8799\n",
            "Epoch 2/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6367 - loss: 0.8206 - val_accuracy: 0.6623 - val_loss: 0.7843\n",
            "Epoch 3/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6869 - loss: 0.7397 - val_accuracy: 0.6700 - val_loss: 0.7755\n",
            "Epoch 4/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6944 - loss: 0.7229 - val_accuracy: 0.6716 - val_loss: 0.7713\n",
            "Epoch 5/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7015 - loss: 0.7086 - val_accuracy: 0.6749 - val_loss: 0.7675\n",
            "Epoch 6/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7094 - loss: 0.6914 - val_accuracy: 0.6774 - val_loss: 0.7637\n",
            "Epoch 7/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7224 - loss: 0.6677 - val_accuracy: 0.6786 - val_loss: 0.7612\n",
            "Epoch 8/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.6369 - val_accuracy: 0.6770 - val_loss: 0.7627\n",
            "Epoch 9/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7513 - loss: 0.6029 - val_accuracy: 0.6805 - val_loss: 0.7736\n",
            "Epoch 10/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7680 - loss: 0.5667 - val_accuracy: 0.6781 - val_loss: 0.7939\n",
            "Epoch 11/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7874 - loss: 0.5281 - val_accuracy: 0.6724 - val_loss: 0.8264\n",
            "Epoch 12/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8050 - loss: 0.4869 - val_accuracy: 0.6669 - val_loss: 0.8711\n",
            "Epoch 13/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8246 - loss: 0.4438 - val_accuracy: 0.6645 - val_loss: 0.9363\n",
            "Epoch 14/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8464 - loss: 0.3987 - val_accuracy: 0.6584 - val_loss: 1.0265\n",
            "Epoch 15/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8676 - loss: 0.3521 - val_accuracy: 0.6560 - val_loss: 1.1473\n",
            "Epoch 16/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8858 - loss: 0.3098 - val_accuracy: 0.6573 - val_loss: 1.2360\n",
            "Epoch 17/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8919 - loss: 0.2876 - val_accuracy: 0.6549 - val_loss: 1.3203\n",
            "Epoch 18/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9073 - loss: 0.2496 - val_accuracy: 0.6457 - val_loss: 1.4545\n",
            "Epoch 19/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9213 - loss: 0.2160 - val_accuracy: 0.6518 - val_loss: 1.6138\n",
            "Epoch 20/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9250 - loss: 0.2027 - val_accuracy: 0.6404 - val_loss: 1.7261\n",
            "Epoch 21/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9363 - loss: 0.1663 - val_accuracy: 0.6427 - val_loss: 1.9326\n",
            "Epoch 22/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9426 - loss: 0.1513 - val_accuracy: 0.6503 - val_loss: 1.9597\n",
            "Epoch 23/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9465 - loss: 0.1413 - val_accuracy: 0.6452 - val_loss: 2.1447\n",
            "Epoch 24/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9488 - loss: 0.1478 - val_accuracy: 0.6500 - val_loss: 2.0955\n",
            "Epoch 25/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9618 - loss: 0.1015 - val_accuracy: 0.6434 - val_loss: 2.3844\n",
            "Epoch 26/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9627 - loss: 0.1018 - val_accuracy: 0.6511 - val_loss: 2.3690\n",
            "Epoch 27/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9648 - loss: 0.0923 - val_accuracy: 0.6556 - val_loss: 2.3148\n",
            "Epoch 28/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9744 - loss: 0.0746 - val_accuracy: 0.6534 - val_loss: 2.4898\n",
            "Epoch 29/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9766 - loss: 0.0638 - val_accuracy: 0.6483 - val_loss: 2.4734\n",
            "Epoch 30/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9759 - loss: 0.0661 - val_accuracy: 0.6553 - val_loss: 2.7138\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kc/dev/2249/CSI4506/Devoir3/venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4021 - loss: 1.0636 - val_accuracy: 0.4623 - val_loss: 1.0078\n",
            "Epoch 2/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4714 - loss: 0.9623 - val_accuracy: 0.5072 - val_loss: 0.9524\n",
            "Epoch 3/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5417 - loss: 0.9124 - val_accuracy: 0.5434 - val_loss: 0.9213\n",
            "Epoch 4/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5765 - loss: 0.8795 - val_accuracy: 0.5588 - val_loss: 0.9058\n",
            "Epoch 5/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5905 - loss: 0.8610 - val_accuracy: 0.5686 - val_loss: 0.8977\n",
            "Epoch 6/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6014 - loss: 0.8461 - val_accuracy: 0.5735 - val_loss: 0.8913\n",
            "Epoch 7/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6132 - loss: 0.8283 - val_accuracy: 0.5785 - val_loss: 0.8860\n",
            "Epoch 8/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6298 - loss: 0.8014 - val_accuracy: 0.5831 - val_loss: 0.8833\n",
            "Epoch 9/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6529 - loss: 0.7629 - val_accuracy: 0.5954 - val_loss: 0.8761\n",
            "Epoch 10/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6779 - loss: 0.7210 - val_accuracy: 0.5987 - val_loss: 0.8759\n",
            "Epoch 11/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6990 - loss: 0.6797 - val_accuracy: 0.6025 - val_loss: 0.8869\n",
            "Epoch 12/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7173 - loss: 0.6397 - val_accuracy: 0.6053 - val_loss: 0.9082\n",
            "Epoch 13/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 946us/step - accuracy: 0.7379 - loss: 0.6006 - val_accuracy: 0.6064 - val_loss: 0.9442\n",
            "Epoch 14/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7581 - loss: 0.5616 - val_accuracy: 0.6031 - val_loss: 1.0021\n",
            "Epoch 15/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7781 - loss: 0.5233 - val_accuracy: 0.6040 - val_loss: 1.0555\n",
            "Epoch 16/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7950 - loss: 0.4864 - val_accuracy: 0.5990 - val_loss: 1.1242\n",
            "Epoch 17/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8048 - loss: 0.4655 - val_accuracy: 0.5970 - val_loss: 1.1564\n",
            "Epoch 18/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8083 - loss: 0.4570 - val_accuracy: 0.5983 - val_loss: 1.1964\n",
            "Epoch 19/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8284 - loss: 0.4139 - val_accuracy: 0.6004 - val_loss: 1.2364\n",
            "Epoch 20/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8372 - loss: 0.3939 - val_accuracy: 0.6022 - val_loss: 1.2541\n",
            "Epoch 21/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8499 - loss: 0.3683 - val_accuracy: 0.5970 - val_loss: 1.3595\n",
            "Epoch 22/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8612 - loss: 0.3446 - val_accuracy: 0.5979 - val_loss: 1.4521\n",
            "Epoch 23/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8673 - loss: 0.3376 - val_accuracy: 0.5962 - val_loss: 1.4695\n",
            "Epoch 24/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8831 - loss: 0.3010 - val_accuracy: 0.5725 - val_loss: 1.6651\n",
            "Epoch 25/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8922 - loss: 0.2838 - val_accuracy: 0.5866 - val_loss: 1.7318\n",
            "Epoch 26/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8927 - loss: 0.2764 - val_accuracy: 0.5902 - val_loss: 1.7010\n",
            "Epoch 27/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9009 - loss: 0.2620 - val_accuracy: 0.5970 - val_loss: 1.7457\n",
            "Epoch 28/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9062 - loss: 0.2528 - val_accuracy: 0.5972 - val_loss: 1.7470\n",
            "Epoch 29/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9222 - loss: 0.2237 - val_accuracy: 0.5893 - val_loss: 1.9308\n",
            "Epoch 30/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 968us/step - accuracy: 0.9325 - loss: 0.1978 - val_accuracy: 0.5927 - val_loss: 1.8840\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kc/dev/2249/CSI4506/Devoir3/venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4437 - loss: 1.0202 - val_accuracy: 0.5429 - val_loss: 0.9497\n",
            "Epoch 2/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5982 - loss: 0.8838 - val_accuracy: 0.6623 - val_loss: 0.7911\n",
            "Epoch 3/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6854 - loss: 0.7478 - val_accuracy: 0.6670 - val_loss: 0.7795\n",
            "Epoch 4/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6923 - loss: 0.7290 - val_accuracy: 0.6699 - val_loss: 0.7760\n",
            "Epoch 5/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6988 - loss: 0.7165 - val_accuracy: 0.6738 - val_loss: 0.7733\n",
            "Epoch 6/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7053 - loss: 0.7034 - val_accuracy: 0.6762 - val_loss: 0.7703\n",
            "Epoch 7/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7145 - loss: 0.6869 - val_accuracy: 0.6765 - val_loss: 0.7657\n",
            "Epoch 8/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 980us/step - accuracy: 0.7249 - loss: 0.6634 - val_accuracy: 0.6803 - val_loss: 0.7586\n",
            "Epoch 9/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7406 - loss: 0.6310 - val_accuracy: 0.6817 - val_loss: 0.7572\n",
            "Epoch 10/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7577 - loss: 0.5934 - val_accuracy: 0.6823 - val_loss: 0.7662\n",
            "Epoch 11/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7759 - loss: 0.5529 - val_accuracy: 0.6773 - val_loss: 0.7912\n",
            "Epoch 12/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7954 - loss: 0.5100 - val_accuracy: 0.6654 - val_loss: 0.8402\n",
            "Epoch 13/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8165 - loss: 0.4647 - val_accuracy: 0.6515 - val_loss: 0.9169\n",
            "Epoch 14/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8385 - loss: 0.4175 - val_accuracy: 0.6430 - val_loss: 1.0246\n",
            "Epoch 15/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8610 - loss: 0.3689 - val_accuracy: 0.6336 - val_loss: 1.1557\n",
            "Epoch 16/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8830 - loss: 0.3192 - val_accuracy: 0.6279 - val_loss: 1.3239\n",
            "Epoch 17/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8988 - loss: 0.2787 - val_accuracy: 0.6296 - val_loss: 1.4700\n",
            "Epoch 18/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9010 - loss: 0.2650 - val_accuracy: 0.6313 - val_loss: 1.5305\n",
            "Epoch 19/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2277 - val_accuracy: 0.6302 - val_loss: 1.6437\n",
            "Epoch 20/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9225 - loss: 0.2058 - val_accuracy: 0.6040 - val_loss: 1.9338\n",
            "Epoch 21/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9311 - loss: 0.1860 - val_accuracy: 0.6390 - val_loss: 1.7668\n",
            "Epoch 22/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9382 - loss: 0.1644 - val_accuracy: 0.6344 - val_loss: 1.9305\n",
            "Epoch 23/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9455 - loss: 0.1440 - val_accuracy: 0.6032 - val_loss: 2.4556\n",
            "Epoch 24/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9445 - loss: 0.1538 - val_accuracy: 0.6411 - val_loss: 2.0481\n",
            "Epoch 25/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 994us/step - accuracy: 0.9606 - loss: 0.1099 - val_accuracy: 0.6418 - val_loss: 2.2237\n",
            "Epoch 26/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9615 - loss: 0.1027 - val_accuracy: 0.6473 - val_loss: 2.3529\n",
            "Epoch 27/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9617 - loss: 0.1057 - val_accuracy: 0.6462 - val_loss: 2.5219\n",
            "Epoch 28/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9703 - loss: 0.0778 - val_accuracy: 0.6403 - val_loss: 2.5993\n",
            "Epoch 29/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9723 - loss: 0.0780 - val_accuracy: 0.6292 - val_loss: 2.6223\n",
            "Epoch 30/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9716 - loss: 0.0761 - val_accuracy: 0.6407 - val_loss: 2.5580\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/kc/dev/2249/CSI4506/Devoir3/venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4993 - loss: 1.0046 - val_accuracy: 0.6317 - val_loss: 0.8269\n",
            "Epoch 2/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6700 - loss: 0.7737 - val_accuracy: 0.6632 - val_loss: 0.7846\n",
            "Epoch 3/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6879 - loss: 0.7365 - val_accuracy: 0.6650 - val_loss: 0.7773\n",
            "Epoch 4/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6955 - loss: 0.7218 - val_accuracy: 0.6693 - val_loss: 0.7732\n",
            "Epoch 5/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7029 - loss: 0.7086 - val_accuracy: 0.6712 - val_loss: 0.7692\n",
            "Epoch 6/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7109 - loss: 0.6926 - val_accuracy: 0.6734 - val_loss: 0.7649\n",
            "Epoch 7/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7211 - loss: 0.6705 - val_accuracy: 0.6751 - val_loss: 0.7608\n",
            "Epoch 8/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7344 - loss: 0.6406 - val_accuracy: 0.6800 - val_loss: 0.7586\n",
            "Epoch 9/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7534 - loss: 0.6066 - val_accuracy: 0.6801 - val_loss: 0.7643\n",
            "Epoch 10/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7704 - loss: 0.5700 - val_accuracy: 0.6774 - val_loss: 0.7819\n",
            "Epoch 11/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7872 - loss: 0.5312 - val_accuracy: 0.6746 - val_loss: 0.8124\n",
            "Epoch 12/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8046 - loss: 0.4904 - val_accuracy: 0.6695 - val_loss: 0.8556\n",
            "Epoch 13/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8259 - loss: 0.4477 - val_accuracy: 0.6647 - val_loss: 0.9155\n",
            "Epoch 14/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8459 - loss: 0.4039 - val_accuracy: 0.6549 - val_loss: 0.9982\n",
            "Epoch 15/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8653 - loss: 0.3592 - val_accuracy: 0.6452 - val_loss: 1.1108\n",
            "Epoch 16/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8821 - loss: 0.3186 - val_accuracy: 0.6466 - val_loss: 1.1949\n",
            "Epoch 17/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8896 - loss: 0.2951 - val_accuracy: 0.6414 - val_loss: 1.2768\n",
            "Epoch 18/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9008 - loss: 0.2677 - val_accuracy: 0.6279 - val_loss: 1.4272\n",
            "Epoch 19/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9164 - loss: 0.2259 - val_accuracy: 0.6360 - val_loss: 1.6029\n",
            "Epoch 20/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9232 - loss: 0.2149 - val_accuracy: 0.6434 - val_loss: 1.5871\n",
            "Epoch 21/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9336 - loss: 0.1775 - val_accuracy: 0.6357 - val_loss: 1.8179\n",
            "Epoch 22/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9375 - loss: 0.1683 - val_accuracy: 0.6364 - val_loss: 1.9675\n",
            "Epoch 23/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9471 - loss: 0.1405 - val_accuracy: 0.6199 - val_loss: 2.3550\n",
            "Epoch 24/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9494 - loss: 0.1378 - val_accuracy: 0.6437 - val_loss: 2.0653\n",
            "Epoch 25/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9589 - loss: 0.1105 - val_accuracy: 0.6396 - val_loss: 2.2109\n",
            "Epoch 26/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9644 - loss: 0.0975 - val_accuracy: 0.6422 - val_loss: 2.3613\n",
            "Epoch 27/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9648 - loss: 0.0988 - val_accuracy: 0.6520 - val_loss: 2.4298\n",
            "Epoch 28/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9680 - loss: 0.0889 - val_accuracy: 0.6480 - val_loss: 2.5256\n",
            "Epoch 29/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9720 - loss: 0.0756 - val_accuracy: 0.6475 - val_loss: 2.6536\n",
            "Epoch 30/30\n",
            "\u001b[1m1822/1822\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9748 - loss: 0.0706 - val_accuracy: 0.6495 - val_loss: 2.6243\n"
          ]
        }
      ],
      "source": [
        "for model_size, hist in histories.items():\n",
        "    histories2[(1, False, model_size)] = hist\n",
        "\n",
        "for num_layers in [2, 3]: # we skip num_layers = 1 as we already found results for it \n",
        "    for pyramid in [True, False]:\n",
        "        for starting_size in [4, 8, 16]:\n",
        "            model = create_model(num_layers, pyramid, starting_size)\n",
        "            history = model.fit(X_train_scaled, y_train, validation_data=(X_valid_scaled, y_valid), epochs=30)\n",
        "            histories2[(num_layers, pyramid, starting_size)] = history\n",
        "            \n",
        "for pyramid in [True, False]:\n",
        "    for starting_size in [8, 16, 32]:\n",
        "        model = create_model(4, pyramid, starting_size) # num_layers = 4\n",
        "        history = model.fit(X_train_scaled, y_train, validation_data=(X_valid_scaled, y_valid), epochs=30)\n",
        "        histories2[(4, pyramid, starting_size)] = history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Sélectionnez un de vos modèles qui illustre le surapprentissage. Dans nos expériences, nous avons facilement construit un modèle atteignant près de 100 % de précision sur les données d'entraînement, sans aucune amélioration similaire sur l'ensemble de validation. Présentez ce réseau de neurones avec ses graphiques de précision et de perte. Expliquez pourquoi vous concluez que le modèle surapprend."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Code cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Fonction d'activation**.\n",
        "\n",
        "    - Présentez les résultats pour une des configurations mentionnées ci-dessus en variant la fonction d'activation. Testez au moins `relu` (le paramètre par défaut) et `sigmoid`. Le choix du modèle spécifique, y compris le nombre de couches et de nœuds, est à votre discrétion. Documentez vos observations en conséquence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Code cell\n",
        "activations = [\"relu\", \"tanh\", \"sigmoid\"]\n",
        "for activation in activations:\n",
        "    model = tf.keras.Sequential()\n",
        "    \n",
        "    # we choose the number of nodes, layers and whether to use pyramid or not based on the previous results\n",
        "    model.add(tf.keras.layers.Dense(462, input_dim=462, activation=activation))\n",
        "    model.add(tf.keras.layers.Dense(4))\n",
        "    model.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
        "    \n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
        "    history = model.fit(X_train_scaled, y_train, validation_data=(X_valid_scaled, y_valid), epochs=50)\n",
        "    \n",
        "    pd.DataFrame(history.history).plot(\n",
        "        grid=True, figsize=(10, 7), title=\"Loss and Accuracy\", style=\"--.\", ylim=(0, 2)\n",
        "    )\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.title(f\"Activation function: {activation}\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Régularisation** dans les réseaux de neurones est une technique utilisée pour éviter le surapprentissage.\n",
        "\n",
        "    - Une technique consiste à ajouter une pénalité à la fonction de perte pour décourager les modèles excessivement complexes. Appliquez une pénalité `l2` à certaines ou à toutes les couches. Soyez prudent, car des pénalités trop agressives se sont révélées problématiques dans nos expériences. Commencez avec la valeur par défaut `l2` de 0.01, puis réduisez-la à 0.001 et à 1e-4. Sélectionnez un modèle spécifique parmi les expériences ci-dessus et présentez un cas où vous avez réussi à réduire le surapprentissage. Incluez une paire de graphiques comparant les résultats avec et sans régularisation. Expliquez votre raisonnement pour conclure que le surapprentissage a été réduit. N'espérez pas éliminer complètement le surapprentissage. Encore une fois, il s'agit d'un ensemble de données difficile à travailler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Code cell\n",
        "\n",
        "for penalty_val in [0.01, 0.001, 0.0001]:\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Dense(462, input_dim=462, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(penalty_val)))\n",
        "    model.add(tf.keras.layers.Dense(8), kernel_regularizer=tf.keras.regularizers.l2(penalty_val))\n",
        "    model.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
        "    \n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
        "    history = model.fit(X_train_scaled, y_train, validation_data=(X_valid_scaled, y_valid), epochs=50)\n",
        "    \n",
        "    pd.DataFrame(history.history).plot(\n",
        "        grid=True, figsize=(10, 7), title=\"Loss and Accuracy\", style=\"--.\", ylim=(0, 2)\n",
        "    )\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.title(f\"Penalty value: {penalty_val}\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Les couches de **dropout** sont une technique de régularisation dans les réseaux de neurones, où un sous-ensemble aléatoire de neurones est temporairement retiré pendant l'entraînement. Cela aide à éviter le surapprentissage en favorisant la redondance et en améliorant la capacité du réseau à généraliser sur de nouvelles données. Sélectionnez un modèle spécifique parmi les expériences ci-dessus, où vous avez plusieurs couches, et expérimentez l'ajout d'une ou de plusieurs couches de dropout dans votre réseau. Testez deux taux différents, par exemple 0.25 et 0.5. Documentez vos observations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Code cell\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(462, input_dim=462, activation='relu'))\n",
        "tf.keras.layers.Dropout(0.5)\n",
        "model.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
        "history = model.fit(X_train_scaled, y_train, validation_data=(X_valid_scaled, y_valid), epochs=50)\n",
        "\n",
        "pd.DataFrame(history.history).plot(\n",
        "    grid=True, figsize=(10, 7), title=\"Loss and Accuracy\", style=\"--.\", ylim=(0, 2)\n",
        ")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Résumez vos expériences en utilisant une représentation graphique telle que la Figure 6.15 [sur cette page](https://egallic.fr/Enseignement/ML/ECB/book/deep-learning.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Code cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- L'**arrêt anticipé** est une technique de régularisation lors de l'entraînement d'un réseau de neurones, où le processus est interrompu lorsque les performances sur l'ensemble de validation commencent à se dégrader, ce qui empêche le réseau d'apprendre le bruit dans les données d'entraînement. Parmi toutes les expériences menées jusqu'à présent, choisissez **une** configuration (le nombre de couches, le nombre de nœuds, la fonction d'activation, la pénalité L2 et les couches de dropout) qui a donné les meilleures performances. Utilisez un graphique de perte et de précision pour déterminer le nombre optimal d'itérations d'entraînement pour ce réseau. Quel est le nombre optimal d'époques pour cette configuration de réseau et pourquoi ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Code cell\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(462, input_dim=462, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(8))\n",
        "model.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
        "history = model.fit(X_train_scaled, y_train, validation_data=(X_valid_scaled, y_valid), epochs=50, callbacks=[early_stop])\n",
        "\n",
        "pd.DataFrame(history.history).plot(\n",
        "    grid=True, figsize=(10, 7), title=\"Loss and Accuracy\", style=\"--.\", ylim=(0, 2)\n",
        ")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.xlabel(\"Epochs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test\n",
        "\n",
        "9. **Comparaison des modèles** :\n",
        "\n",
        "    - Évaluez le modèle de référence sur l'ensemble de test, en utilisant l'ensemble de paramètres optimal identifié lors de la recherche de grille. Appliquez également la meilleure configuration de réseau de neurones à l'ensemble de test.\n",
        "\n",
        "    - Quantifiez les performances du modèle de référence (meilleure configuration d'hyperparamètres) et de votre réseau de neurones (meilleure configuration) en utilisant des métriques telles que la précision, le rappel et le score F1. Comment ces deux modèles se comparent-ils au modèle de base ?\n",
        "\n",
        "    - Fournissez des recommandations sur le(s) modèle(s) à choisir pour cette tâche et justifiez vos choix en fonction des résultats de l'analyse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Code cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Resources"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
